{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS2_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6QSvoq2wWc9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, LSTM\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EDJOwl1zw3aG",
        "outputId": "3f4f1428-ace6-4721-983a-8441e90817c9"
      },
      "source": [
        "train = pd.read_csv('train_gen_2.csv')\n",
        "test = pd.read_csv('test_gen_2.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah wana save n stinge... We shall eat smting...</td>\n",
              "      <td>Yes, I want to save and stinge. We shall eat s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dunno how come cannot go online leh, tt fuji...</td>\n",
              "      <td>I don't know how come I cannot go online. That...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hey come online? We discuss eng with regina</td>\n",
              "      <td>Can you come online? We shall discuss Eng with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ü all go then i go lor... Free one wat...</td>\n",
              "      <td>All go then I go. It is free.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input                                             target\n",
              "0                              Ya. Next week coming.                              Ya. Next week coming.\n",
              "1  Yeah wana save n stinge... We shall eat smting...  Yes, I want to save and stinge. We shall eat s...\n",
              "2    Dunno how come cannot go online leh, tt fuji...  I don't know how come I cannot go online. That...\n",
              "3        Hey come online? We discuss eng with regina  Can you come online? We shall discuss Eng with...\n",
              "4          Ü all go then i go lor... Free one wat...                      All go then I go. It is free."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqnRGnG88LYy",
        "outputId": "40b12dba-e908-4dec-b62b-ffc239af9f66"
      },
      "source": [
        "required_chars = []\n",
        "for char in string.printable:\n",
        "  if ord(char) > 31 and ord(char) < 126:\n",
        "    required_chars.append(char)\n",
        "\n",
        "\n",
        "print(len(required_chars))\n",
        "print(required_chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWM0cCmi7s5D"
      },
      "source": [
        "# Create a dictionary of chars and index value from 1. 0 is reserved for padding by the tokenizer.\n",
        "vocabulary = dict()\n",
        "for i in range(len(required_chars)):\n",
        "  vocabulary[required_chars[i]] = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgItyynh7uWb"
      },
      "source": [
        "# Use \\t as Start of Sentence and \\n as End of Sentence\n",
        "vocabulary['\\n'] = 95\n",
        "vocabulary['\\t'] = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4nfKCXvyDC2"
      },
      "source": [
        "# Characters that were found in train and test set and replaced with the normal english characters.\n",
        "replacements = {'£':'', 'É': 'E', 'Ñ': 'N', 'Ü': 'U', 'à': 'a', 'ä': 'a', 'å': 'a', 'è': 'e', 'é': 'e', 'ì': 'i', 'ñ': 'n', 'ò': 'o', 'ö': 'o', 'ø': 'o', 'ù': 'u', 'ü': 'u',  '“': '\"',  '”': '\"',   '，': ',',   '？': '?' }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oq7MzJqyKa2"
      },
      "source": [
        "for old_char, new_char in replacements.items():\n",
        "  train = train.replace(old_char, new_char, regex=True)\n",
        "  test = test.replace(old_char, new_char, regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrFuNLIs2owY"
      },
      "source": [
        "# Adding the \\t and \\n as part of start and end of sentence\n",
        "train['target_ip'] = '\\t' + train['target'].astype(str)\n",
        "train['target_op'] =  train['target'].astype(str) + '\\n'\n",
        "\n",
        "test['target_ip'] = '\\t' + test['target'].astype(str)\n",
        "test['target_op'] =  test['target'].astype(str) + '\\n'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG58E_dY3JaN"
      },
      "source": [
        "train = train.drop(['target'], axis=1)\n",
        "test = test.drop(['target'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pn9P1Pl52rMl",
        "outputId": "5c8e5a25-591f-4e42-d498-4f12ac9cb008"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target_ip</th>\n",
              "      <th>target_op</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "      <td>\\tYa. Next week coming.</td>\n",
              "      <td>Ya. Next week coming.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah wana save n stinge... We shall eat smting...</td>\n",
              "      <td>\\tYes, I want to save and stinge. We shall eat...</td>\n",
              "      <td>Yes, I want to save and stinge. We shall eat s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dunno how come cannot go online leh, tt fuji...</td>\n",
              "      <td>\\tI don't know how come I cannot go online. Th...</td>\n",
              "      <td>I don't know how come I cannot go online. That...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hey come online? We discuss eng with regina</td>\n",
              "      <td>\\tCan you come online? We shall discuss Eng wi...</td>\n",
              "      <td>Can you come online? We shall discuss Eng with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U all go then i go lor... Free one wat...</td>\n",
              "      <td>\\tAll go then I go. It is free.</td>\n",
              "      <td>All go then I go. It is free.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input  ...                                          target_op\n",
              "0                              Ya. Next week coming.  ...                            Ya. Next week coming.\\n\n",
              "1  Yeah wana save n stinge... We shall eat smting...  ...  Yes, I want to save and stinge. We shall eat s...\n",
              "2    Dunno how come cannot go online leh, tt fuji...  ...  I don't know how come I cannot go online. That...\n",
              "3        Hey come online? We discuss eng with regina  ...  Can you come online? We shall discuss Eng with...\n",
              "4          U all go then i go lor... Free one wat...  ...                    All go then I go. It is free.\\n\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dccV3FWe3IbF"
      },
      "source": [
        "train.iloc[0]['target_ip']= str(train.iloc[0]['target_ip'])+'\\n'\n",
        "train.iloc[0]['target_op']= str(train.iloc[0]['target_op'])+'\\n'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Ub9wTxyymO",
        "outputId": "889a46d6-be15-4159-815b-ea01c005740a"
      },
      "source": [
        "# Calculating the maximum length of among all the sentences which will be useful for padding.\n",
        "max_length_encoder = train['input'].map(len).max()\n",
        "\n",
        "print(max_length_encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AagDwgGoiRBI"
      },
      "source": [
        "max_length_encoder = 170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1M6VC2ixr6J",
        "outputId": "987252de-32e7-4278-db02-f3a731670d4c"
      },
      "source": [
        "max_length_decoder = max( train['target_ip'].map(len).max(), train['target_op'].map(len).max())\n",
        "print(max_length_decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brw3mDkGxemO"
      },
      "source": [
        "# Tokenizer for the raw input and target output\n",
        "tokenizer_raw_ip = Tokenizer(\n",
        "    char_level=True,\n",
        "    lower=False,\n",
        "    filters=None\n",
        ")\n",
        "\n",
        "tokenizer_target_ip = Tokenizer(\n",
        "    char_level=True,\n",
        "    lower=False,\n",
        "    filters=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6VhrB0BxkS_"
      },
      "source": [
        "tokenizer_raw_ip.fit_on_texts(train['input'].values)\n",
        "tokenizer_target_ip.fit_on_texts(train['target_ip'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OMsgwWd72wz"
      },
      "source": [
        "# Replacing the vocabulary of the trained index to a vocabulary mentioned in the research paper\n",
        "tokenizer_target_ip.word_index = vocabulary\n",
        "tokenizer_raw_ip.word_index = vocabulary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCobtx0TDkqS",
        "outputId": "cdbbfd5d-27d4-4369-b8f7-300a61469bdf"
      },
      "source": [
        "target_vocab_size=len(tokenizer_target_ip.word_index.keys())\n",
        "print(target_vocab_size)\n",
        "input_vocab_size=len(tokenizer_raw_ip.word_index.keys())\n",
        "print(input_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyh-g2_A1BsV"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "\n",
        "        self.encoder_output = 0\n",
        "        self.hidden_state = 0\n",
        "        self.cell_state = 0\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        self.encoder_embedding_layer = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length, mask_zero=True, name=\"encoder_embedding_layer\")\n",
        "\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.encoder_lstm_layer =  LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "\n",
        "        embedding = self.encoder_embedding_layer(input_sequence)\n",
        "        self.encoder_output, self.hidden_state, self.cell_state = self.encoder_lstm_layer(embedding)\n",
        "\n",
        "        return self.encoder_output, self.hidden_state, self.cell_state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISiiCAv41Juc"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function = scoring_function\n",
        "    self.att_units = att_units\n",
        "\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "  \n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      self.dot_products = []\n",
        "\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      self.W_a = tf.keras.layers.Dense(self.att_units)\n",
        "      self.general = []\n",
        "\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.W1 = tf.keras.layers.Dense(self.att_units)\n",
        "      self.W2 = tf.keras.layers.Dense(self.att_units)\n",
        "      self.V = tf.keras.layers.Dense(1)\n",
        "      \n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    output = []\n",
        "\n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here        \n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2)\n",
        "        output = tf.keras.layers.Dot(axes=(2, 1))([encoder_output, decoder_hidden_state])        \n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2)\n",
        "        \n",
        "        output = self.W_a(encoder_output)\n",
        "        \n",
        "        output = tf.keras.layers.Dot(axes=(2, 1))([output, decoder_hidden_state])\n",
        "        \n",
        "        \n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)      \n",
        "        output = self.V(tf.nn.tanh(self.W1(decoder_hidden_state) + self.W2(encoder_output)))\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(output, axis=1)\n",
        "    context_vector = tf.keras.layers.Dot(axes=(1, 1))([attention_weights, encoder_output])\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj-HgOkU1LOl"
      },
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "      self.tar_vocab_size = tar_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "\n",
        "      self.decoder_output = 0\n",
        "      self.decoder_final_state_h = 0 \n",
        "      self.decoder_final_state_c = 0\n",
        "\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        \n",
        "      self.decoder_embedding_layer = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"decoder_embedding_layer\")\n",
        "\n",
        "      self.decoder_lstm_layer = LSTM(self.dec_units, return_state=True, return_sequences=True, name=\"onestep_Decoder\")\n",
        "\n",
        "      self.dense_layer = Dense(tar_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    embedding_layer = self.decoder_embedding_layer(input_to_decoder)\n",
        "    attention=Attention(self.score_fun, self.att_units)\n",
        "    context_vector, attention_weights = attention(state_h, encoder_output)\n",
        "    embedding_layer = embedding_layer[:,0,:]\n",
        "    concat_input = tf.concat([context_vector, embedding_layer], 1)\n",
        "    concat_input = tf.expand_dims(concat_input, axis=1)\n",
        "    decoder_output, decoder_h, decoder_c = self.decoder_lstm_layer(concat_input)\n",
        "    output = self.dense_layer(decoder_output)\n",
        "    output = output[:,0,:]\n",
        "    return output, decoder_h, decoder_c, attention_weights, context_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XXycM9A1M1E"
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29SvJdA_1N2t"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "\n",
        "      self.one_step_decoder = One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units, self.score_fun, self.att_units)\n",
        "\n",
        "    def call(self, input_to_decoder, encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        # Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        # Create a tensor array as shown in the reference notebook\n",
        "        outputs = tf.TensorArray(tf.float32, size=200, name='output_array')\n",
        "\n",
        "        #Iterate till the length of the decoder input\n",
        "        for timestep in range(200):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "            output, decoder_h, decoder_c, attention_weights, context_vector = self.one_step_decoder(input_to_decoder[:,timestep:timestep+1], encoder_output, decoder_hidden_state, decoder_cell_state)\n",
        "\n",
        "            outputs = outputs.write(timestep, output)\n",
        "            \n",
        "        # Return the tensor array\n",
        "        outputs = tf.transpose(outputs.stack(),[1,0,2])\n",
        "  \n",
        "        return outputs\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvmy-_rK1O_8"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self, enc_vocab_size, enc_embedding_size, enc_lstm_size, enc_input_length, dec_vocab_size, dec_embedding_dim, dec_input_length, dec_units , score_fun , att_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # Encoder\n",
        "    self.enc_vocab_size = enc_vocab_size\n",
        "    self.enc_embedding_size = enc_embedding_size\n",
        "    self.enc_lstm_size = enc_lstm_size\n",
        "    self.enc_input_length = enc_input_length\n",
        "\n",
        "    # Decoder\n",
        "    self.dec_vocab_size = dec_vocab_size\n",
        "    self.dec_embedding_dim = dec_embedding_dim\n",
        "    self.dec_input_length = dec_input_length\n",
        "    self.dec_units = dec_units\n",
        "    self.score_fun = score_fun\n",
        "    self.att_units = att_units\n",
        "\n",
        "    #Intialize objects from encoder decoder\n",
        "    self.encoder = Encoder(self.enc_vocab_size, self.enc_embedding_size, self.enc_lstm_size, self.enc_input_length)\n",
        "\n",
        "    self.decoder = Decoder(self.dec_vocab_size, self.dec_embedding_dim, self.dec_input_length, self.dec_units , self.score_fun , self.att_units)\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "  def call(self, data):\n",
        "    input, output = data[0], data[1]\n",
        "        \n",
        "    # Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    encoder_output, state_h, state_c = self.encoder(input)\n",
        "\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    dec_output = self.decoder(output, encoder_output, state_h, state_c)\n",
        "  \n",
        "    # return the decoder output\n",
        "    return dec_output\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z5Wte1-1SWl"
      },
      "source": [
        "# Do once normal loss function works\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def custom_lossfunction(real, pred):\n",
        "\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
        "  \n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgez3_YT1VIF"
      },
      "source": [
        "# Creating a data pipeline\n",
        "class Dataset:\n",
        "    def __init__(self, data, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder,max_length_decoder):\n",
        "        self.encoder_inps = data['input'].values\n",
        "        self.decoder_inps = data['target_ip'].values\n",
        "        self.decoder_outs = data['target_op'].values\n",
        "        self.tokenizer_target_ip = tokenizer_target_ip\n",
        "        self.tokenizer_raw_ip = tokenizer_raw_ip\n",
        "        self.max_length_encoder = max_length_encoder\n",
        "        self.max_length_decoder = max_length_decoder\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tokenizer_raw_ip.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_length_encoder, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6G-PDSJ1V61",
        "outputId": "03b05d21-46b1-4576-807f-e64d297b280c"
      },
      "source": [
        "train_dataset = Dataset(train, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)\n",
        "test_dataset  = Dataset(test, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=64)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 185) (64, 200) (64, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie7CpwJF7-Of",
        "outputId": "b9fdcac1-deb8-453d-9eb0-46d89e97f26e"
      },
      "source": [
        "train_dataloader[0][1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzaQ30Py22YO"
      },
      "source": [
        "# Reduce learning rate based on the validation loss\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.99, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGmm0vdA2804"
      },
      "source": [
        "checkpoint_filepath = 'model_1'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xko06I9c1Xv3"
      },
      "source": [
        "model_dot = encoder_decoder(enc_vocab_size = input_vocab_size+1, enc_embedding_size = 20, enc_lstm_size = 100, enc_input_length = max_length_encoder, \\\n",
        "                        dec_vocab_size = target_vocab_size+1, dec_embedding_dim = 20, dec_input_length = max_length_decoder, dec_units = 100, score_fun = 'general', att_units=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01, clipnorm=5.0)\n",
        "\n",
        "model_dot.compile(optimizer=optimizer,loss=custom_lossfunction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k7Uk7QX2uyV",
        "outputId": "1f83aca2-6490-4409-d40c-82f08e233ed5"
      },
      "source": [
        "train_steps=train.shape[0]//64\n",
        "valid_steps=test.shape[0]//20\n",
        "\n",
        "print(train_steps, valid_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7AOvfXkie2W"
      },
      "source": [
        "model_dot.load_weights(\"model_1\")\n",
        "\n",
        "model_dot.evaluate(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnNzZbNm5zaS"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=0.01, clipnorm=5.0)\n",
        "\n",
        "model_dot.compile(optimizer=optimizer,loss=custom_lossfunction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d96pFDe-1Yl8",
        "outputId": "5473850f-2620-4f99-a58a-1adbb53df229"
      },
      "source": [
        "model_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=260, validation_data=test_dataloader, validation_steps=valid_steps, callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "model_dot.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 1.2201 - val_loss: 0.6315\n",
            "Epoch 2/260\n",
            "116/116 [==============================] - 374s 3s/step - loss: 0.9218 - val_loss: 0.6164\n",
            "Epoch 3/260\n",
            "116/116 [==============================] - 372s 3s/step - loss: 0.9062 - val_loss: 0.6125\n",
            "Epoch 4/260\n",
            "116/116 [==============================] - 369s 3s/step - loss: 0.8987 - val_loss: 0.6105\n",
            "Epoch 5/260\n",
            "116/116 [==============================] - 374s 3s/step - loss: 0.8967 - val_loss: 0.6098\n",
            "Epoch 6/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 0.9025 - val_loss: 0.6067\n",
            "Epoch 7/260\n",
            "116/116 [==============================] - 369s 3s/step - loss: 0.8861 - val_loss: 0.6072\n",
            "Epoch 8/260\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.8784 - val_loss: 0.6057\n",
            "Epoch 9/260\n",
            "116/116 [==============================] - 374s 3s/step - loss: 0.8928 - val_loss: 0.6047\n",
            "Epoch 10/260\n",
            "116/116 [==============================] - 370s 3s/step - loss: 0.8989 - val_loss: 0.6024\n",
            "Epoch 11/260\n",
            "116/116 [==============================] - 367s 3s/step - loss: 0.8831 - val_loss: 0.5977\n",
            "Epoch 12/260\n",
            "116/116 [==============================] - 368s 3s/step - loss: 0.8723 - val_loss: 0.5990\n",
            "Epoch 13/260\n",
            "116/116 [==============================] - 369s 3s/step - loss: 0.8657 - val_loss: 0.5940\n",
            "Epoch 14/260\n",
            "116/116 [==============================] - 366s 3s/step - loss: 0.8683 - val_loss: 0.5909\n",
            "Epoch 15/260\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.8509 - val_loss: 0.5880\n",
            "Epoch 16/260\n",
            "116/116 [==============================] - 374s 3s/step - loss: 0.8608 - val_loss: 0.5922\n",
            "Epoch 17/260\n",
            "116/116 [==============================] - 371s 3s/step - loss: 0.8436 - val_loss: 0.5887\n",
            "Epoch 18/260\n",
            "116/116 [==============================] - 377s 3s/step - loss: 0.8380 - val_loss: 0.5815\n",
            "Epoch 19/260\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.8275 - val_loss: 0.5833\n",
            "Epoch 20/260\n",
            "116/116 [==============================] - 372s 3s/step - loss: 0.8150 - val_loss: 0.5845\n",
            "Epoch 21/260\n",
            "116/116 [==============================] - 372s 3s/step - loss: 0.8169 - val_loss: 0.5784\n",
            "Epoch 22/260\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.8103 - val_loss: 0.5793\n",
            "Epoch 23/260\n",
            "116/116 [==============================] - 373s 3s/step - loss: 0.8096 - val_loss: 0.5749\n",
            "Epoch 24/260\n",
            "116/116 [==============================] - 376s 3s/step - loss: 0.7946 - val_loss: 0.5794\n",
            "Epoch 25/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 0.7992 - val_loss: 0.5765\n",
            "Epoch 26/260\n",
            "116/116 [==============================] - 381s 3s/step - loss: 0.7908 - val_loss: 0.5728\n",
            "Epoch 27/260\n",
            "116/116 [==============================] - 377s 3s/step - loss: 0.7811 - val_loss: 0.5742\n",
            "Epoch 28/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 0.7813 - val_loss: 0.5789\n",
            "Epoch 29/260\n",
            "116/116 [==============================] - 378s 3s/step - loss: 0.7834 - val_loss: 0.5754\n",
            "Epoch 30/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 0.7792 - val_loss: 0.5759\n",
            "Epoch 31/260\n",
            "116/116 [==============================] - 375s 3s/step - loss: 0.7612 - val_loss: 0.5690\n",
            "Epoch 32/260\n",
            "116/116 [==============================] - 376s 3s/step - loss: 0.7627 - val_loss: 0.5806\n",
            "Epoch 33/260\n",
            "116/116 [==============================] - 379s 3s/step - loss: 0.7634 - val_loss: 0.5716\n",
            "Epoch 34/260\n",
            "116/116 [==============================] - 377s 3s/step - loss: 0.7625 - val_loss: 0.5666\n",
            "Epoch 35/260\n",
            "116/116 [==============================] - 372s 3s/step - loss: 0.7659 - val_loss: 0.5769\n",
            "Epoch 36/260\n",
            "116/116 [==============================] - 370s 3s/step - loss: 0.7628 - val_loss: 0.5636\n",
            "Epoch 37/260\n",
            "116/116 [==============================] - 368s 3s/step - loss: 0.7562 - val_loss: 0.5732\n",
            "Epoch 38/260\n",
            "116/116 [==============================] - 367s 3s/step - loss: 0.7381 - val_loss: 0.5746\n",
            "Epoch 39/260\n",
            "116/116 [==============================] - 368s 3s/step - loss: 0.7448 - val_loss: 0.5740\n",
            "Epoch 40/260\n",
            "116/116 [==============================] - 368s 3s/step - loss: 0.7473 - val_loss: 0.5750\n",
            "Epoch 41/260\n",
            "116/116 [==============================] - 367s 3s/step - loss: 0.7426 - val_loss: 0.5781\n",
            "Epoch 42/260\n",
            "116/116 [==============================] - 366s 3s/step - loss: 0.7367 - val_loss: 0.5802\n",
            "Epoch 43/260\n",
            "116/116 [==============================] - 367s 3s/step - loss: 0.7392 - val_loss: 0.5798\n",
            "Epoch 44/260\n",
            "116/116 [==============================] - 369s 3s/step - loss: 0.7528 - val_loss: 0.5806\n",
            "Epoch 45/260\n",
            "116/116 [==============================] - 369s 3s/step - loss: 0.7412 - val_loss: 0.5720\n",
            "Epoch 46/260\n",
            "116/116 [==============================] - 365s 3s/step - loss: 0.7364 - val_loss: 0.5781\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "Epoch 47/260\n",
            "  5/116 [>.............................] - ETA: 5:53 - loss: 0.7317"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-28a4d1788dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_dot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_dot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-b45d7abae154>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Decoder initial states are encoder final states, Initialize it accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Pass the decoder sequence,encoder_output,decoder states to Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# return the decoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-8cfdba93a036>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Call onestepdecoder for each token in decoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Store the output in tensorarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-209859d2a2f7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, state_h, state_c)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mconcat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-ca8a913a4602>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, decoder_hidden_state, encoder_output)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdecoder_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         dtype=self._compute_dtype_object)\n\u001b[0m\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3377\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[0;32m-> 3379\u001b[0;31m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 675\u001b[0;31m         _ctx, \"BiasAdd\", name, value, bias, \"data_format\", data_format)\n\u001b[0m\u001b[1;32m    676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORgObjVYxHCh",
        "outputId": "499c8dc0-d589-4ffc-beb0-675e12bd97ba"
      },
      "source": [
        "model_dot.load_weights(\"model_1\")\n",
        "\n",
        "model_dot.evaluate(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.5720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5720122456550598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWsx_0CMxglW"
      },
      "source": [
        "start_index = tokenizer_target_ip.word_index['\\t']\n",
        "end_index = tokenizer_target_ip.word_index['\\n']\n",
        "DECODER_SEQ_LEN = 200\n",
        "max_len = 200\n",
        "\n",
        "\n",
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  encoder_seq = tokenizer_raw_ip.texts_to_sequences([input_sentence])\n",
        "  encoder_seq = pad_sequences(encoder_seq, maxlen=max_length_encoder, dtype='int32', padding='post')\n",
        "\n",
        "\n",
        "  enc_output, enc_state_h, enc_state_c = model_dot.layers[0](encoder_seq)\n",
        "\n",
        "  dec_input = tf.expand_dims([tokenizer_target_ip.word_index['\\t']], 0)\n",
        "\n",
        "  input_state = [enc_state_h, enc_state_c]\n",
        "  output_word = []\n",
        "  # attention_plot = np.zeros((20, 20))\n",
        "\n",
        "\n",
        "  for i in range(DECODER_SEQ_LEN):\n",
        "\n",
        "      output, state_h, state_c, attention_weights, context_vector = model_dot.layers[1].one_step_decoder(dec_input, enc_output, input_state[0], input_state[1])\n",
        "\n",
        "      input_state = [state_h, state_c]\n",
        "\n",
        "      output_word_index = np.argmax(output)\n",
        "\n",
        "      for key, value in tokenizer_target_ip.word_index.items():\n",
        "\n",
        "         if output_word_index == value:\n",
        "              output_word.append(key)\n",
        "\n",
        "      dec_input = np.reshape(output_word_index, (1, 1))\n",
        "\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    \n",
        "      # attention_plot[i] = attention_weights.numpy()\n",
        "\n",
        "\n",
        "      if dec_input == tokenizer_target_ip.word_index['\\n']:\n",
        "        break\n",
        "\n",
        "\n",
        "  predicted_sentence = ''.join(output_word)\n",
        "\n",
        "  # attention_plot = attention_plot[:len(predicted_sentence.split(' ')), :len(input_sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, input_sentence.split(' '), predicted_sentence.split(' ')) # Comment out if you do need the plots of attention weights.\n",
        "\n",
        "  print('Input_sentence:', input_sentence)\n",
        "  print('Predicted_sentence:',predicted_sentence)\n",
        "\n",
        "  \n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O44cyM9yxk3t",
        "outputId": "d3c400d0-7ee8-4ee8-c2a0-9b0583a9bad4"
      },
      "source": [
        "predicted_sentences = []\n",
        "actual_sentences = []\n",
        "\n",
        "for i, row in test.iterrows():\n",
        "    output = predict(row['input'])\n",
        "    predicted_sentences.append(output)\n",
        "    english_out = row['target_op'].split()\n",
        "    actual_sentences.append(english_out)\n",
        "    sentence = ''.join(output)\n",
        "    print('Input Sentence:',row['input'])\n",
        "    print('Predicted Sentence:',sentence)\n",
        "    print('Original English sentence:', row['target_op'])\n",
        "    print('*'*30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input_sentence: Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
            "Predicted_sentence: Not's athat a t's that'm at's inow m ng t I at t not's d mbengomed t'm atham That's bus t's t ino am ame boto atow athat's I bumert d tha gom at's g t's Tham fot's m fott'mbe t'mid t athat's I t t's a\n",
            "Input Sentence: Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
            "Predicted Sentence: Not's athat a t's that'm at's inow m ng t I at t not's d mbengomed t'm atham That's bus t's t ino am ame boto atow athat's I bumert d tha gom at's g t's Tham fot's m fott'mbe t'mid t athat's I t t's a\n",
            "Original English sentence: That's better now, I got a roast down me! I'd be better if I had a few drinks down me too! Good Indian?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Watch wat?\n",
            "Predicted_sentence: Wh wat watchat wat watche tchat watche watche wat watchat wat wat wat watchat wat wat wat wat wat t wat wat watchatchat wathat wat wat watchat wat wat wat wat watche watchat watchat t wat wat wat wat \n",
            "Input Sentence: Watch wat?\n",
            "Predicted Sentence: Wh wat watchat wat watche tchat watche watche wat watchat wat wat wat watchat wat wat wat wat wat t wat wat watchatchat wathat wat wat watchat wat wat wat wat watche watchat watchat t wat wat wat wat \n",
            "Original English sentence: Watch what?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Oh dat...hehe.Why r u so interested?\n",
            "Predicted_sentence: Hahe the Oke te tourent s youryou the toure therenthen I thay? touree sthe Hes date tinthayo He wayoure tey, Oksthayoure st thatou Hahat t He y. Hahe youre y. ste He yourere das whe te dat hendato He \n",
            "Input Sentence: Oh dat...hehe.Why r u so interested?\n",
            "Predicted Sentence: Hahe the Oke te tourent s youryou the toure therenthen I thay? touree sthe Hes date tinthayo He wayoure tey, Oksthayoure st thatou Hahat t He y. Hahe youre y. ste He yourere das whe te dat hendato He \n",
            "Original English sentence: Oh that. Hehe. Why are you so interested?\n",
            "\n",
            "******************************\n",
            "Input_sentence: hai\n",
            "Predicted_sentence: He t t the thathe he t t the the t he the thahe thathe thathe hat thathe thathe he t the t the the the that t the he thathe he thathe t the he thave t the thathe t the t he the the t the the t the t t\n",
            "Input Sentence: hai\n",
            "Predicted Sentence: He t t the thathe he t t the the t he the thahe thathe thathe hat thathe thathe he t the t the the the that t the he thathe he thathe t the he thave t the thathe t the t he the the t the the t the t t\n",
            "Original English sentence: Hi.\n",
            "\n",
            "******************************\n",
            "Input_sentence: ask more abt me?\n",
            "Predicted_sentence: Min at ore ame are ame at athat are athe at ame at are me me atou are at me athe alllre at ame athe ale me ore ame at amabe ale ame at are athe ale ale ame athe ame me at me atore athe ating me at ath\n",
            "Input Sentence: ask more abt me?\n",
            "Predicted Sentence: Min at ore ame are ame at athat are athe at ame at are me me atou are at me athe alllre at ame athe ale me ore ame at amabe ale ame at are athe ale ale ame athe ame me at me atore athe ating me at ath\n",
            "Original English sentence: Ask more about me?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey jiayin... Can bring 10 bucks tmr, it's 4 wawa's bdae...\n",
            "Predicted_sentence: Han Juban Jung! Jun ba Jus foror Jang ban bantr Junkan bang bankang ban Juban bann baratroran cks banks bang barobang Jan Jan Jan Can Jutranks ban batraran Jus foban for y Cang ichan bang batrang Jang\n",
            "Input Sentence: Hey jiayin... Can bring 10 bucks tmr, it's 4 wawa's bdae...\n",
            "Predicted Sentence: Han Juban Jung! Jun ba Jus foror Jang ban bantr Junkan bang bankang ban Juban bann baratroran cks banks bang barobang Jan Jan Jan Can Jutranks ban batraran Jus foban for y Cang ichan bang batrang Jang\n",
            "Original English sentence: Hey Jiayin. Can you bring 10 bucks tomorrow? It's for Wawa's birthday.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Wanna intro...Joey?\n",
            "Predicted_sentence: Went int Jo Jodou Jouche Jod Jodouse intou Jo Jont todo wantontoucant Jont want We t Jodo want indowant Jont We Jou tontontro Jou Jontont wanto w Jodant Jodont Jont w wantront Jod w Jont t Jo wantodst\n",
            "Input Sentence: Wanna intro...Joey?\n",
            "Predicted Sentence: Went int Jo Jodou Jouche Jod Jodouse intou Jo Jont todo wantontoucant Jont want We t Jodo want indowant Jont We Jou tontontro Jou Jontont wanto w Jodant Jodont Jont w wantront Jod w Jont t Jo wantodst\n",
            "Original English sentence: Want to introduce, Joey?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey call me when you are abt to reach? I'm going muji to see see look look\n",
            "Predicted_sentence: He to to to to se to s go s s I'l lo I'me sto l e I'm g al tom are toke che g tome sto acakicacache acache sHe songoou He the lllls yo s acan tou s so to che to che g an too to so me so to to tome me \n",
            "Input Sentence: Hey call me when you are abt to reach? I'm going muji to see see look look\n",
            "Predicted Sentence: He to to to to se to s go s s I'l lo I'me sto l e I'm g al tom are toke che g tome sto acakicacache acache sHe songoou He the lllls yo s acan tou s so to che to che g an too to so me so to to tome me \n",
            "Original English sentence: Hey, call me when you are about to reach? I'm going to muji to have a look.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Contraction line ...\n",
            "Predicted_sentence: Cane cion chine that can care the chiane ine cacane cane te caneathe te tre tre catone catin ion the the cecane cone ine t tontone ine cathe Le tine cat cane Le chinethine catiacane catone tone che co\n",
            "Input Sentence: Contraction line ...\n",
            "Predicted Sentence: Cane cion chine that can care the chiane ine cacane cane te caneathe te tre tre catone catin ion the the cecane cone ine t tontone ine cathe Le tine cat cane Le chinethine catiacane catone tone che co\n",
            "Original English sentence: Contraction line.\n",
            "\n",
            "******************************\n",
            "Input_sentence: He say dun tink they need part timer...How? U go crepes n cream ask la...Hereen 1...\n",
            "Predicted_sentence: He y tese the pllleee the Hee yow therere Henknk thime tee theenk t thextee He there Heene He the thew se te He He theee te thinow plllw plllanow thathe the cayow He theyore therd g te t theyow gow pe\n",
            "Input Sentence: He say dun tink they need part timer...How? U go crepes n cream ask la...Hereen 1...\n",
            "Predicted Sentence: He y tese the pllleee the Hee yow therere Henknk thime tee theenk t thextee He there Heene He the thew se te He He theee te thinow plllw plllanow thathe the cayow He theyore therd g te t theyow gow pe\n",
            "Original English sentence: He says he doesn't think they need part timer. How? Go Creps and Cream ask. The one in Hereen.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Can i come in half an hr later... I nd to bath....Gee...\n",
            "Predicted_sentence: Ok ind he cat can in in ber be lan can lan can for t tou cat can can can tome n gound Le I ll cand t I fomed in ind catoumomp be n cand in ind t I cand he be I be I g go l I co t cacand 7. OK. in me m\n",
            "Input Sentence: Can i come in half an hr later... I nd to bath....Gee...\n",
            "Predicted Sentence: Ok ind he cat can in in ber be lan can lan can for t tou cat can can can tome n gound Le I ll cand t I fomed in ind catoumomp be n cand in ind t I cand he be I be I g go l I co t cacand 7. OK. in me m\n",
            "Original English sentence: Can I come in half an hour later? I need to bath.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Wat u doing?\n",
            "Predicted_sentence: What dou you dou you t dou you dou dou doing you dou you you you d dou you you you you d you doing dou yoing d dou yoid you yoing yoing dou you you dou doing you you what wat yoing you dou yoin you yo\n",
            "Input Sentence: Wat u doing?\n",
            "Predicted Sentence: What dou you dou you t dou you dou dou doing you dou you you you d dou you you you you d you doing dou yoing d dou yoid you yoing yoing dou you you dou doing you you what wat yoing you dou yoin you yo\n",
            "Original English sentence: What are you doing?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Once i pick up it'll just cut off... SBS or something? are you a member of something? :)\n",
            "Predicted_sentence: Any s of ousichatut put oubou of URe or oust put pur of Whe out onk wicof pur ou alichoubl ame ou wicou of OKin of p of out outitithine of f I puput ou ou puthinyoutith of I sthe outith ut of of wichi\n",
            "Input Sentence: Once i pick up it'll just cut off... SBS or something? are you a member of something? :)\n",
            "Predicted Sentence: Any s of ousichatut put oubou of URe or oust put pur of Whe out onk wicof pur ou alichoubl ame ou wicou of OKin of p of out outitithine of f I puput ou ou puthinyoutith of I sthe outith ut of of wichi\n",
            "Original English sentence: Once I pick up it'll just cut off. SBS or something? Are you a member of something?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey u will be in orchard right? I'm going to ask mei they all if they've bought the frame... If not we go ikea and buy one? Coz v few pieces left.can complete\n",
            "Predicted_sentence: He g in f y in g in ge in t g s t go t were t the in in in gon the s ithe thean tot ano wick cket wethe in in gorethe in s for in the in got t g f y, g al g y t g t t be ile tothe g f f o it got cke a\n",
            "Input Sentence: Hey u will be in orchard right? I'm going to ask mei they all if they've bought the frame... If not we go ikea and buy one? Coz v few pieces left.can complete\n",
            "Predicted Sentence: He g in f y in g in ge in t g s t go t were t the in in in gon the s ithe thean tot ano wick cket wethe in in gorethe in s for in the in got t g f y, g al g y t g t t be ile tothe g f f o it got cke a\n",
            "Original English sentence: Hey you will be in Orchard right? I'm going to ask Mei and the rest if they've bought the frame. If not we'll go to Ikea and buy one? Because there are very few pieces left. Can complete.\n",
            "\n",
            "******************************\n",
            "Input_sentence: But cun lah... go next wk? Act where u wanna go?\n",
            "Predicted_sentence: Cat wan t wat wachandou want but wangout wat go go go wangowat cherch chawat go wau watrowat wangowan wangout gout want gou But wat wan go be go wat gou wanch gou goint ware ch gowat want bur ck in Bu\n",
            "Input Sentence: But cun lah... go next wk? Act where u wanna go?\n",
            "Predicted Sentence: Cat wan t wat wachandou want but wangout wat go go go wangowat cherch chawat go wau watrowat wangowan wangout gout want gou But wat wan go be go wat gou wanch gou goint ware ch gowat want bur ck in Bu\n",
            "Original English sentence: But please come. Are you going next week? Ask you where you want to go.\n",
            "\n",
            "******************************\n",
            "Input_sentence: ok!\n",
            "Predicted_sentence: I athe athe athe athe athe athe athe athe athe athe athe ayou athe athe athe athe at athe athe athe athe athe athe athe athe the athe the the athe athe athe athe the athe athek at athe athe athe athe \n",
            "Input Sentence: ok!\n",
            "Predicted Sentence: I athe athe athe athe athe athe athe athe athe athe athe ayou athe athe athe athe at athe athe athe athe athe athe athe athe the athe the the athe athe athe athe the athe athek at athe athe athe athe \n",
            "Original English sentence: Ok!\n",
            "\n",
            "******************************\n",
            "Input_sentence: So where n wat time u wan meet?\n",
            "Predicted_sentence: Se whe whe wat whan whe whe whe whe whe whawat whayoe what n whe what whe who whe whe what t yo whant wawhet nt what n whe what t whe t what t nt wat t t whe wan t whe whe me whe whe what what what me\n",
            "Input Sentence: So where n wat time u wan meet?\n",
            "Predicted Sentence: Se whe whe wat whan whe whe whe whe whe whawat whayoe what n whe what whe who whe whe what t yo whant wawhet nt what n whe what t whe t what t nt wat t t whe wan t whe whe me whe whe what what what me\n",
            "Original English sentence: So where and what time do you want to meet?\n",
            "\n",
            "******************************\n",
            "Input_sentence: You want a not? I will go buy for you... I reached orchard already\n",
            "Predicted_sentence: Doutou I me you anou al at re ano yo anou balreacallll you yotoupin al al gou I y fit anout re and yo ano reanou reano you you you yochant I ry you antillre yout anoread wad allll wat me reanoud bal y\n",
            "Input Sentence: You want a not? I will go buy for you... I reached orchard already\n",
            "Predicted Sentence: Doutou I me you anou al at re ano yo anou balreacallll you yotoupin al al gou I y fit anout re and yo ano reanou reano you you you yochant I ry you antillre yout anoread wad allll wat me reanoud bal y\n",
            "Original English sentence: You want or not? I will go to buy for you. I reached Orchard already.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hi, u male\n",
            "Predicted_sentence: Hing you you you you you you you t?\n",
            "\n",
            "Input Sentence: Hi, u male\n",
            "Predicted Sentence: Hing you you you you you you you t?\n",
            "\n",
            "Original English sentence: Hi, are you male?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Where are you\n",
            "Predicted_sentence: Whe you you yowhe you you you you are you you are you you you you are you you are you you you you are you are you you you you are you you are you you you you you are you yowhe are you are you you you \n",
            "Input Sentence: Where are you\n",
            "Predicted Sentence: Whe you you yowhe you you you you are you you are you you you you are you you are you you you you are you are you you you you are you you are you you you you you are you yowhe are you are you you you \n",
            "Original English sentence: Where are you?\n",
            "\n",
            "******************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vT2tzjowX3v"
      },
      "source": [
        "# Attention with OHE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pd0xLlxIwZoq",
        "outputId": "d6a410e0-bf6e-40e4-c9ab-77a9e0732cb2"
      },
      "source": [
        "train = pd.read_csv('train_2.csv')\n",
        "test = pd.read_csv('test_2.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah wana save n stinge... We shall eat smting...</td>\n",
              "      <td>Yes, I want to save and stinge. We shall eat s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dunno how come cannot go online leh, tt fuji...</td>\n",
              "      <td>I don't know how come I cannot go online. That...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hey come online? We discuss eng with regina</td>\n",
              "      <td>Can you come online? We shall discuss Eng with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ü all go then i go lor... Free one wat...</td>\n",
              "      <td>All go then I go. It is free.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input                                             target\n",
              "0                              Ya. Next week coming.                              Ya. Next week coming.\n",
              "1  Yeah wana save n stinge... We shall eat smting...  Yes, I want to save and stinge. We shall eat s...\n",
              "2    Dunno how come cannot go online leh, tt fuji...  I don't know how come I cannot go online. That...\n",
              "3        Hey come online? We discuss eng with regina  Can you come online? We shall discuss Eng with...\n",
              "4          Ü all go then i go lor... Free one wat...                      All go then I go. It is free."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2nu1DS8wZot",
        "outputId": "73ba0354-b3f0-40ff-ebef-6ccbac7ed3a5"
      },
      "source": [
        "required_chars = []\n",
        "for char in string.printable:\n",
        "  if ord(char) > 31 and ord(char) < 126:\n",
        "    required_chars.append(char)\n",
        "\n",
        "\n",
        "print(len(required_chars))\n",
        "print(required_chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d47anxmwZov"
      },
      "source": [
        "# Create a dictionary of chars and index value from 1. 0 is reserved for padding by the tokenizer.\n",
        "vocabulary = dict()\n",
        "for i in range(len(required_chars)):\n",
        "  vocabulary[required_chars[i]] = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzdEvoTewZow"
      },
      "source": [
        "# Use \\t as Start of Sentence and \\n as End of Sentence\n",
        "vocabulary['\\n'] = 95\n",
        "vocabulary['\\t'] = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrteQnn-wZox"
      },
      "source": [
        "# Characters that were found in train and test set and replaced with the normal english characters.\n",
        "replacements = {'£':'', 'É': 'E', 'Ñ': 'N', 'Ü': 'U', 'à': 'a', 'ä': 'a', 'å': 'a', 'è': 'e', 'é': 'e', 'ì': 'i', 'ñ': 'n', 'ò': 'o', 'ö': 'o', 'ø': 'o', 'ù': 'u', 'ü': 'u',  '“': '\"',  '”': '\"',   '，': ',',   '？': '?' }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzYB-ZJfwZoy"
      },
      "source": [
        "for old_char, new_char in replacements.items():\n",
        "  train = train.replace(old_char, new_char, regex=True)\n",
        "  test = test.replace(old_char, new_char, regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_W6pFniwZoz"
      },
      "source": [
        "# Adding the \\t and \\n as part of start and end of sentence\n",
        "train['target_ip'] = '\\t' + train['target'].astype(str)\n",
        "train['target_op'] =  train['target'].astype(str) + '\\n'\n",
        "\n",
        "test['target_ip'] = '\\t' + test['target'].astype(str)\n",
        "test['target_op'] =  test['target'].astype(str) + '\\n'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VBAcVeDwZo0"
      },
      "source": [
        "train = train.drop(['target'], axis=1)\n",
        "test = test.drop(['target'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "H0rTLkhgwZo1",
        "outputId": "79d482e0-3697-438f-a979-25d36c22fc3b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target_ip</th>\n",
              "      <th>target_op</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ya. Next week coming.</td>\n",
              "      <td>\\tYa. Next week coming.</td>\n",
              "      <td>Ya. Next week coming.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah wana save n stinge... We shall eat smting...</td>\n",
              "      <td>\\tYes, I want to save and stinge. We shall eat...</td>\n",
              "      <td>Yes, I want to save and stinge. We shall eat s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dunno how come cannot go online leh, tt fuji...</td>\n",
              "      <td>\\tI don't know how come I cannot go online. Th...</td>\n",
              "      <td>I don't know how come I cannot go online. That...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hey come online? We discuss eng with regina</td>\n",
              "      <td>\\tCan you come online? We shall discuss Eng wi...</td>\n",
              "      <td>Can you come online? We shall discuss Eng with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U all go then i go lor... Free one wat...</td>\n",
              "      <td>\\tAll go then I go. It is free.</td>\n",
              "      <td>All go then I go. It is free.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               input  ...                                          target_op\n",
              "0                              Ya. Next week coming.  ...                            Ya. Next week coming.\\n\n",
              "1  Yeah wana save n stinge... We shall eat smting...  ...  Yes, I want to save and stinge. We shall eat s...\n",
              "2    Dunno how come cannot go online leh, tt fuji...  ...  I don't know how come I cannot go online. That...\n",
              "3        Hey come online? We discuss eng with regina  ...  Can you come online? We shall discuss Eng with...\n",
              "4          U all go then i go lor... Free one wat...  ...                    All go then I go. It is free.\\n\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlbLiJlIwZo2"
      },
      "source": [
        "train.iloc[0]['target_ip']= str(train.iloc[0]['target_ip'])+'\\n'\n",
        "train.iloc[0]['target_op']= str(train.iloc[0]['target_op'])+'\\n'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Crr0U4wZo3",
        "outputId": "abe13301-0dcc-4976-ac1b-9e4f97197bf3"
      },
      "source": [
        "# Calculating the maximum length of among all the sentences which will be useful for padding.\n",
        "max_length_encoder = train['input'].map(len).max()\n",
        "\n",
        "print(max_length_encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vqg8IUmwZo4"
      },
      "source": [
        "max_length_encoder = 170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRGe7S98wZo5",
        "outputId": "ecbaa7b2-bb69-4090-c153-598a9c2476c8"
      },
      "source": [
        "max_length_decoder = max( train['target_ip'].map(len).max(), train['target_op'].map(len).max())\n",
        "print(max_length_decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDg2EfsiwZo6"
      },
      "source": [
        "# Tokenizer for the raw input and target output\n",
        "tokenizer_raw_ip = Tokenizer(\n",
        "    char_level=True,\n",
        "    lower=False,\n",
        "    filters=None\n",
        ")\n",
        "\n",
        "tokenizer_target_ip = Tokenizer(\n",
        "    char_level=True,\n",
        "    lower=False,\n",
        "    filters=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms4DvvS3wZo6"
      },
      "source": [
        "tokenizer_raw_ip.fit_on_texts(train['input'].values)\n",
        "tokenizer_target_ip.fit_on_texts(train['target_ip'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bU2xgMuwZo7"
      },
      "source": [
        "# Replacing the vocabulary of the trained index to a vocabulary mentioned in the research paper\n",
        "tokenizer_target_ip.word_index = vocabulary\n",
        "tokenizer_raw_ip.word_index = vocabulary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3s2EOTQwZo8",
        "outputId": "ab0bb0da-85be-4482-d55e-9b4c39ab965e"
      },
      "source": [
        "target_vocab_size=len(tokenizer_target_ip.word_index.keys())\n",
        "print(target_vocab_size)\n",
        "input_vocab_size=len(tokenizer_raw_ip.word_index.keys())\n",
        "print(input_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n",
            "96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phEbKOMiwZo9"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "\n",
        "        self.encoder_output = 0\n",
        "        self.hidden_state = 0\n",
        "        self.cell_state = 0\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        self.encoder_embedding_layer = Embedding(input_dim=self.inp_vocab_size, output_dim=self.embedding_size, input_length=self.input_length, mask_zero=True, name=\"encoder_embedding_layer\")\n",
        "\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.encoder_lstm_layer =  LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "\n",
        "        # embedding = self.encoder_embedding_layer(input_sequence)\n",
        "        self.encoder_output, self.hidden_state, self.cell_state = self.encoder_lstm_layer(input_sequence)\n",
        "\n",
        "        return self.encoder_output, self.hidden_state, self.cell_state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnaOl3DjwZo-"
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function = scoring_function\n",
        "    self.att_units = att_units\n",
        "\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "  \n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      self.dot_products = []\n",
        "\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      self.W_a = tf.keras.layers.Dense(self.att_units)\n",
        "      self.general = []\n",
        "\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      self.W1 = tf.keras.layers.Dense(self.att_units)\n",
        "      self.W2 = tf.keras.layers.Dense(self.att_units)\n",
        "      self.V = tf.keras.layers.Dense(1)\n",
        "      \n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    output = []\n",
        "\n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here        \n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2)\n",
        "        output = tf.keras.layers.Dot(axes=(2, 1))([encoder_output, decoder_hidden_state])        \n",
        "\n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2)\n",
        "        \n",
        "        output = self.W_a(encoder_output)\n",
        "        \n",
        "        output = tf.keras.layers.Dot(axes=(2, 1))([output, decoder_hidden_state])\n",
        "        \n",
        "        \n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)      \n",
        "        output = self.V(tf.nn.tanh(self.W1(decoder_hidden_state) + self.W2(encoder_output)))\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(output, axis=1)\n",
        "    context_vector = tf.keras.layers.Dot(axes=(1, 1))([attention_weights, encoder_output])\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5FX4SPqwZpB"
      },
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      super().__init__()\n",
        "      self.tar_vocab_size = tar_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "\n",
        "      self.decoder_output = 0\n",
        "      self.decoder_final_state_h = 0 \n",
        "      self.decoder_final_state_c = 0\n",
        "\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        \n",
        "      # self.decoder_embedding_layer = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"decoder_embedding_layer\")\n",
        "\n",
        "      self.decoder_lstm_layer = LSTM(self.dec_units, return_state=True, return_sequences=True, name=\"onestep_Decoder\")\n",
        "\n",
        "      self.dense_layer = Dense(tar_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    # embedding_layer = self.decoder_embedding_layer(input_to_decoder)\n",
        "    attention=Attention(self.score_fun, self.att_units)\n",
        "    context_vector, attention_weights = attention(state_h, encoder_output)\n",
        "    input_to_decoder = input_to_decoder[:,0,:]\n",
        "    concat_input = tf.concat([context_vector, input_to_decoder], 1)\n",
        "    concat_input = tf.expand_dims(concat_input, axis=1)\n",
        "    decoder_output, decoder_h, decoder_c = self.decoder_lstm_layer(concat_input)\n",
        "    output = self.dense_layer(decoder_output)\n",
        "    output = output[:,0,:]\n",
        "    return output, decoder_h, decoder_c, attention_weights, context_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRv6dMApwZpD"
      },
      "source": [
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0hsg-HdwZpE"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "\n",
        "      self.one_step_decoder = One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units, self.score_fun, self.att_units)\n",
        "\n",
        "    def call(self, input_to_decoder, encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        # Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        # Create a tensor array as shown in the reference notebook\n",
        "        outputs = tf.TensorArray(tf.float32, size=200, name='output_array')\n",
        "\n",
        "        #Iterate till the length of the decoder input\n",
        "        for timestep in range(200):\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "            output, decoder_h, decoder_c, attention_weights, context_vector = self.one_step_decoder(input_to_decoder[:,timestep:timestep+1], encoder_output, decoder_hidden_state, decoder_cell_state)\n",
        "\n",
        "            outputs = outputs.write(timestep, output)\n",
        "            \n",
        "        # Return the tensor array\n",
        "        outputs = tf.transpose(outputs.stack(),[1,0,2])\n",
        "  \n",
        "        return outputs\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmd7HT2XwZpG"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self, enc_vocab_size, enc_embedding_size, enc_lstm_size, enc_input_length, dec_vocab_size, dec_embedding_dim, dec_input_length, dec_units , score_fun , att_units):\n",
        "    super().__init__()\n",
        "\n",
        "    # Encoder\n",
        "    self.enc_vocab_size = enc_vocab_size\n",
        "    self.enc_embedding_size = enc_embedding_size\n",
        "    self.enc_lstm_size = enc_lstm_size\n",
        "    self.enc_input_length = enc_input_length\n",
        "\n",
        "    # Decoder\n",
        "    self.dec_vocab_size = dec_vocab_size\n",
        "    self.dec_embedding_dim = dec_embedding_dim\n",
        "    self.dec_input_length = dec_input_length\n",
        "    self.dec_units = dec_units\n",
        "    self.score_fun = score_fun\n",
        "    self.att_units = att_units\n",
        "\n",
        "    #Intialize objects from encoder decoder\n",
        "    self.encoder = Encoder(self.enc_vocab_size, self.enc_embedding_size, self.enc_lstm_size, self.enc_input_length)\n",
        "\n",
        "    self.decoder = Decoder(self.dec_vocab_size, self.dec_embedding_dim, self.dec_input_length, self.dec_units , self.score_fun , self.att_units)\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "  def call(self, data):\n",
        "    input, output = data[0], data[1]\n",
        "        \n",
        "    # Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    encoder_output, state_h, state_c = self.encoder(input)\n",
        "\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    dec_output = self.decoder(output, encoder_output, state_h, state_c)\n",
        "  \n",
        "    # return the decoder output\n",
        "    return dec_output\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO7wOKWZwZpH"
      },
      "source": [
        "# Do once normal loss function works\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def custom_lossfunction(real, pred):\n",
        "\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
        "  \n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdO2TvwEwZpI"
      },
      "source": [
        "# Creating a data pipeline\n",
        "class Dataset:\n",
        "    def __init__(self, data, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder,max_length_decoder):\n",
        "        self.encoder_inps = data['input'].values\n",
        "        self.decoder_inps = data['target_ip'].values\n",
        "        self.decoder_outs = data['target_op'].values\n",
        "        self.tokenizer_target_ip = tokenizer_target_ip\n",
        "        self.tokenizer_raw_ip = tokenizer_raw_ip\n",
        "        self.max_length_encoder = max_length_encoder\n",
        "        self.max_length_decoder = max_length_decoder\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tokenizer_raw_ip.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_length_encoder, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
        "\n",
        "        self.encoder_seq = tf.keras.utils.to_categorical(self.encoder_seq, num_classes=len(tokenizer_raw_ip.word_index.keys())+1)\n",
        "        self.decoder_inp_seq = tf.keras.utils.to_categorical(self.decoder_inp_seq, num_classes=len(tokenizer_target_ip.word_index.keys())+1)\n",
        "        self.decoder_out_seq = tf.keras.utils.to_categorical(self.decoder_out_seq, num_classes=len(tokenizer_target_ip.word_index.keys())+1)\n",
        "        \n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf2pWiDuwZpK",
        "outputId": "84507882-d4e5-4b81-bba3-a5ca29edded5"
      },
      "source": [
        "train_dataset = Dataset(train, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)\n",
        "test_dataset  = Dataset(test, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=64)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=20)\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 161, 97) (64, 200, 97) (64, 200, 97)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Nh1jbVwZpL",
        "outputId": "5c548b39-a504-4de0-8dc4-78d5718e03aa"
      },
      "source": [
        "train_dataloader[0][1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 200, 97)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAguwWjnwZpM"
      },
      "source": [
        "# Reduce learning rate based on the validation loss\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.99, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F471-H8wZpM"
      },
      "source": [
        "checkpoint_filepath = 'model_1'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Mp-wIkwZpQ"
      },
      "source": [
        "model_dot = encoder_decoder(enc_vocab_size = input_vocab_size+1, enc_embedding_size = 20, enc_lstm_size = 100, enc_input_length = max_length_encoder, \\\n",
        "                        dec_vocab_size = target_vocab_size+1, dec_embedding_dim = 20, dec_input_length = max_length_decoder, dec_units = 100, score_fun = 'general', att_units=100)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
        "\n",
        "model_dot.compile(optimizer=optimizer,loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWGRR1rMwZpQ",
        "outputId": "cf013bdf-c6eb-41c2-d58a-0c3e60e8d4a3"
      },
      "source": [
        "train_steps=train.shape[0]//64\n",
        "valid_steps=test.shape[0]//20\n",
        "\n",
        "print(train_steps, valid_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pBtTaXZrwZpS",
        "outputId": "acee3420-c28c-4fdc-8b15-2319192e16eb"
      },
      "source": [
        "model_dot.fit(train_dataloader, steps_per_epoch=train_steps, epochs=260, validation_data=test_dataloader, validation_steps=valid_steps, callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "model_dot.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/260\n",
            "30/30 [==============================] - 91s 3s/step - loss: 10.5619 - val_loss: 15.5027\n",
            "Epoch 2/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 13.4663 - val_loss: 5.3829\n",
            "Epoch 3/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 12.8713 - val_loss: 15.3289\n",
            "Epoch 4/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 14.4223 - val_loss: 14.8175\n",
            "Epoch 5/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 13.8419 - val_loss: 14.9529\n",
            "Epoch 6/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 12.9462 - val_loss: 15.4360\n",
            "Epoch 7/260\n",
            "30/30 [==============================] - 92s 3s/step - loss: 13.8366 - val_loss: 14.9275\n",
            "Epoch 8/260\n",
            "30/30 [==============================] - 91s 3s/step - loss: 14.2341 - val_loss: 15.4417\n",
            "Epoch 9/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 14.9028 - val_loss: 13.5690\n",
            "Epoch 10/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 13.6196 - val_loss: 14.7898\n",
            "Epoch 11/260\n",
            "30/30 [==============================] - 91s 3s/step - loss: 13.2558 - val_loss: 14.3989\n",
            "Epoch 12/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 13.3607 - val_loss: 14.7610\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "Epoch 13/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: 13.7327 - val_loss: 14.3457\n",
            "Epoch 14/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: nan - val_loss: nan\n",
            "Epoch 15/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: nan - val_loss: nan\n",
            "Epoch 16/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: nan - val_loss: nan\n",
            "Epoch 17/260\n",
            "30/30 [==============================] - 90s 3s/step - loss: nan - val_loss: nan\n",
            "Epoch 18/260\n",
            "30/30 [==============================] - 92s 3s/step - loss: nan - val_loss: nan\n",
            "Epoch 19/260\n",
            "29/30 [============================>.] - ETA: 2s - loss: nan"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-28a4d1788dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_dot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_dot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-b45d7abae154>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Decoder initial states are encoder final states, Initialize it accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Pass the decoder sequence,encoder_output,decoder states to Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# return the decoder output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-8cfdba93a036>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Call onestepdecoder for each token in decoder_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Store the output in tensorarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_to_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-83cff7fa1461>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_to_decoder, encoder_output, state_h, state_c)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# embedding_layer = self.decoder_embedding_layer(input_to_decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0minput_to_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_to_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mconcat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_decoder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-ca8a913a4602>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, decoder_hidden_state, encoder_output)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdecoder_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     return super(VarianceScaling, self).__call__(\n\u001b[0;32m--> 410\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     return op(\n\u001b[0;32m-> 1082\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mmaxval_is_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mminval_is_zero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mminval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m       \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1505\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    624\u001b[0m   \"\"\"\n\u001b[1;32m    625\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEdNqfq0wZpT",
        "outputId": "499c8dc0-d589-4ffc-beb0-675e12bd97ba"
      },
      "source": [
        "model_dot.load_weights(\"model_1\")\n",
        "\n",
        "model_dot.evaluate(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.5720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5720122456550598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7pMd_h2wZpU"
      },
      "source": [
        "start_index = tokenizer_target_ip.word_index['\\t']\n",
        "end_index = tokenizer_target_ip.word_index['\\n']\n",
        "DECODER_SEQ_LEN = 200\n",
        "max_len = 200\n",
        "\n",
        "\n",
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  encoder_seq = tokenizer_raw_ip.texts_to_sequences([input_sentence])\n",
        "  encoder_seq = pad_sequences(encoder_seq, maxlen=max_length_encoder, dtype='int32', padding='post')\n",
        "\n",
        "\n",
        "  enc_output, enc_state_h, enc_state_c = model_dot.layers[0](encoder_seq)\n",
        "\n",
        "  dec_input = tf.expand_dims([tokenizer_target_ip.word_index['\\t']], 0)\n",
        "\n",
        "  input_state = [enc_state_h, enc_state_c]\n",
        "  output_word = []\n",
        "  # attention_plot = np.zeros((20, 20))\n",
        "\n",
        "\n",
        "  for i in range(DECODER_SEQ_LEN):\n",
        "\n",
        "      output, state_h, state_c, attention_weights, context_vector = model_dot.layers[1].one_step_decoder(dec_input, enc_output, input_state[0], input_state[1])\n",
        "\n",
        "      input_state = [state_h, state_c]\n",
        "\n",
        "      output_word_index = np.argmax(output)\n",
        "\n",
        "      for key, value in tokenizer_target_ip.word_index.items():\n",
        "\n",
        "         if output_word_index == value:\n",
        "              output_word.append(key)\n",
        "\n",
        "      dec_input = np.reshape(output_word_index, (1, 1))\n",
        "\n",
        "      attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    \n",
        "      # attention_plot[i] = attention_weights.numpy()\n",
        "\n",
        "\n",
        "      if dec_input == tokenizer_target_ip.word_index['\\n']:\n",
        "        break\n",
        "\n",
        "\n",
        "  predicted_sentence = ''.join(output_word)\n",
        "\n",
        "  # attention_plot = attention_plot[:len(predicted_sentence.split(' ')), :len(input_sentence.split(' '))]\n",
        "  # plot_attention(attention_plot, input_sentence.split(' '), predicted_sentence.split(' ')) # Comment out if you do need the plots of attention weights.\n",
        "\n",
        "  print('Input_sentence:', input_sentence)\n",
        "  print('Predicted_sentence:',predicted_sentence)\n",
        "\n",
        "  \n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-p2cz33wZpV",
        "outputId": "d3c400d0-7ee8-4ee8-c2a0-9b0583a9bad4"
      },
      "source": [
        "predicted_sentences = []\n",
        "actual_sentences = []\n",
        "\n",
        "for i, row in test.iterrows():\n",
        "    output = predict(row['input'])\n",
        "    predicted_sentences.append(output)\n",
        "    english_out = row['target_op'].split()\n",
        "    actual_sentences.append(english_out)\n",
        "    sentence = ''.join(output)\n",
        "    print('Input Sentence:',row['input'])\n",
        "    print('Predicted Sentence:',sentence)\n",
        "    print('Original English sentence:', row['target_op'])\n",
        "    print('*'*30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input_sentence: Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
            "Predicted_sentence: Not's athat a t's that'm at's inow m ng t I at t not's d mbengomed t'm atham That's bus t's t ino am ame boto atow athat's I bumert d tha gom at's g t's Tham fot's m fott'mbe t'mid t athat's I t t's a\n",
            "Input Sentence: Mmm thats better now i got a roast down me! i'd b better if i had a few drinks down me 2! Good indian?\n",
            "Predicted Sentence: Not's athat a t's that'm at's inow m ng t I at t not's d mbengomed t'm atham That's bus t's t ino am ame boto atow athat's I bumert d tha gom at's g t's Tham fot's m fott'mbe t'mid t athat's I t t's a\n",
            "Original English sentence: That's better now, I got a roast down me! I'd be better if I had a few drinks down me too! Good Indian?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Watch wat?\n",
            "Predicted_sentence: Wh wat watchat wat watche tchat watche watche wat watchat wat wat wat watchat wat wat wat wat wat t wat wat watchatchat wathat wat wat watchat wat wat wat wat watche watchat watchat t wat wat wat wat \n",
            "Input Sentence: Watch wat?\n",
            "Predicted Sentence: Wh wat watchat wat watche tchat watche watche wat watchat wat wat wat watchat wat wat wat wat wat t wat wat watchatchat wathat wat wat watchat wat wat wat wat watche watchat watchat t wat wat wat wat \n",
            "Original English sentence: Watch what?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Oh dat...hehe.Why r u so interested?\n",
            "Predicted_sentence: Hahe the Oke te tourent s youryou the toure therenthen I thay? touree sthe Hes date tinthayo He wayoure tey, Oksthayoure st thatou Hahat t He y. Hahe youre y. ste He yourere das whe te dat hendato He \n",
            "Input Sentence: Oh dat...hehe.Why r u so interested?\n",
            "Predicted Sentence: Hahe the Oke te tourent s youryou the toure therenthen I thay? touree sthe Hes date tinthayo He wayoure tey, Oksthayoure st thatou Hahat t He y. Hahe youre y. ste He yourere das whe te dat hendato He \n",
            "Original English sentence: Oh that. Hehe. Why are you so interested?\n",
            "\n",
            "******************************\n",
            "Input_sentence: hai\n",
            "Predicted_sentence: He t t the thathe he t t the the t he the thahe thathe thathe hat thathe thathe he t the t the the the that t the he thathe he thathe t the he thave t the thathe t the t he the the t the the t the t t\n",
            "Input Sentence: hai\n",
            "Predicted Sentence: He t t the thathe he t t the the t he the thahe thathe thathe hat thathe thathe he t the t the the the that t the he thathe he thathe t the he thave t the thathe t the t he the the t the the t the t t\n",
            "Original English sentence: Hi.\n",
            "\n",
            "******************************\n",
            "Input_sentence: ask more abt me?\n",
            "Predicted_sentence: Min at ore ame are ame at athat are athe at ame at are me me atou are at me athe alllre at ame athe ale me ore ame at amabe ale ame at are athe ale ale ame athe ame me at me atore athe ating me at ath\n",
            "Input Sentence: ask more abt me?\n",
            "Predicted Sentence: Min at ore ame are ame at athat are athe at ame at are me me atou are at me athe alllre at ame athe ale me ore ame at amabe ale ame at are athe ale ale ame athe ame me at me atore athe ating me at ath\n",
            "Original English sentence: Ask more about me?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey jiayin... Can bring 10 bucks tmr, it's 4 wawa's bdae...\n",
            "Predicted_sentence: Han Juban Jung! Jun ba Jus foror Jang ban bantr Junkan bang bankang ban Juban bann baratroran cks banks bang barobang Jan Jan Jan Can Jutranks ban batraran Jus foban for y Cang ichan bang batrang Jang\n",
            "Input Sentence: Hey jiayin... Can bring 10 bucks tmr, it's 4 wawa's bdae...\n",
            "Predicted Sentence: Han Juban Jung! Jun ba Jus foror Jang ban bantr Junkan bang bankang ban Juban bann baratroran cks banks bang barobang Jan Jan Jan Can Jutranks ban batraran Jus foban for y Cang ichan bang batrang Jang\n",
            "Original English sentence: Hey Jiayin. Can you bring 10 bucks tomorrow? It's for Wawa's birthday.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Wanna intro...Joey?\n",
            "Predicted_sentence: Went int Jo Jodou Jouche Jod Jodouse intou Jo Jont todo wantontoucant Jont want We t Jodo want indowant Jont We Jou tontontro Jou Jontont wanto w Jodant Jodont Jont w wantront Jod w Jont t Jo wantodst\n",
            "Input Sentence: Wanna intro...Joey?\n",
            "Predicted Sentence: Went int Jo Jodou Jouche Jod Jodouse intou Jo Jont todo wantontoucant Jont want We t Jodo want indowant Jont We Jou tontontro Jou Jontont wanto w Jodant Jodont Jont w wantront Jod w Jont t Jo wantodst\n",
            "Original English sentence: Want to introduce, Joey?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey call me when you are abt to reach? I'm going muji to see see look look\n",
            "Predicted_sentence: He to to to to se to s go s s I'l lo I'me sto l e I'm g al tom are toke che g tome sto acakicacache acache sHe songoou He the lllls yo s acan tou s so to che to che g an too to so me so to to tome me \n",
            "Input Sentence: Hey call me when you are abt to reach? I'm going muji to see see look look\n",
            "Predicted Sentence: He to to to to se to s go s s I'l lo I'me sto l e I'm g al tom are toke che g tome sto acakicacache acache sHe songoou He the lllls yo s acan tou s so to che to che g an too to so me so to to tome me \n",
            "Original English sentence: Hey, call me when you are about to reach? I'm going to muji to have a look.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Contraction line ...\n",
            "Predicted_sentence: Cane cion chine that can care the chiane ine cacane cane te caneathe te tre tre catone catin ion the the cecane cone ine t tontone ine cathe Le tine cat cane Le chinethine catiacane catone tone che co\n",
            "Input Sentence: Contraction line ...\n",
            "Predicted Sentence: Cane cion chine that can care the chiane ine cacane cane te caneathe te tre tre catone catin ion the the cecane cone ine t tontone ine cathe Le tine cat cane Le chinethine catiacane catone tone che co\n",
            "Original English sentence: Contraction line.\n",
            "\n",
            "******************************\n",
            "Input_sentence: He say dun tink they need part timer...How? U go crepes n cream ask la...Hereen 1...\n",
            "Predicted_sentence: He y tese the pllleee the Hee yow therere Henknk thime tee theenk t thextee He there Heene He the thew se te He He theee te thinow plllw plllanow thathe the cayow He theyore therd g te t theyow gow pe\n",
            "Input Sentence: He say dun tink they need part timer...How? U go crepes n cream ask la...Hereen 1...\n",
            "Predicted Sentence: He y tese the pllleee the Hee yow therere Henknk thime tee theenk t thextee He there Heene He the thew se te He He theee te thinow plllw plllanow thathe the cayow He theyore therd g te t theyow gow pe\n",
            "Original English sentence: He says he doesn't think they need part timer. How? Go Creps and Cream ask. The one in Hereen.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Can i come in half an hr later... I nd to bath....Gee...\n",
            "Predicted_sentence: Ok ind he cat can in in ber be lan can lan can for t tou cat can can can tome n gound Le I ll cand t I fomed in ind catoumomp be n cand in ind t I cand he be I be I g go l I co t cacand 7. OK. in me m\n",
            "Input Sentence: Can i come in half an hr later... I nd to bath....Gee...\n",
            "Predicted Sentence: Ok ind he cat can in in ber be lan can lan can for t tou cat can can can tome n gound Le I ll cand t I fomed in ind catoumomp be n cand in ind t I cand he be I be I g go l I co t cacand 7. OK. in me m\n",
            "Original English sentence: Can I come in half an hour later? I need to bath.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Wat u doing?\n",
            "Predicted_sentence: What dou you dou you t dou you dou dou doing you dou you you you d dou you you you you d you doing dou yoing d dou yoid you yoing yoing dou you you dou doing you you what wat yoing you dou yoin you yo\n",
            "Input Sentence: Wat u doing?\n",
            "Predicted Sentence: What dou you dou you t dou you dou dou doing you dou you you you d dou you you you you d you doing dou yoing d dou yoid you yoing yoing dou you you dou doing you you what wat yoing you dou yoin you yo\n",
            "Original English sentence: What are you doing?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Once i pick up it'll just cut off... SBS or something? are you a member of something? :)\n",
            "Predicted_sentence: Any s of ousichatut put oubou of URe or oust put pur of Whe out onk wicof pur ou alichoubl ame ou wicou of OKin of p of out outitithine of f I puput ou ou puthinyoutith of I sthe outith ut of of wichi\n",
            "Input Sentence: Once i pick up it'll just cut off... SBS or something? are you a member of something? :)\n",
            "Predicted Sentence: Any s of ousichatut put oubou of URe or oust put pur of Whe out onk wicof pur ou alichoubl ame ou wicou of OKin of p of out outitithine of f I puput ou ou puthinyoutith of I sthe outith ut of of wichi\n",
            "Original English sentence: Once I pick up it'll just cut off. SBS or something? Are you a member of something?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hey u will be in orchard right? I'm going to ask mei they all if they've bought the frame... If not we go ikea and buy one? Coz v few pieces left.can complete\n",
            "Predicted_sentence: He g in f y in g in ge in t g s t go t were t the in in in gon the s ithe thean tot ano wick cket wethe in in gorethe in s for in the in got t g f y, g al g y t g t t be ile tothe g f f o it got cke a\n",
            "Input Sentence: Hey u will be in orchard right? I'm going to ask mei they all if they've bought the frame... If not we go ikea and buy one? Coz v few pieces left.can complete\n",
            "Predicted Sentence: He g in f y in g in ge in t g s t go t were t the in in in gon the s ithe thean tot ano wick cket wethe in in gorethe in s for in the in got t g f y, g al g y t g t t be ile tothe g f f o it got cke a\n",
            "Original English sentence: Hey you will be in Orchard right? I'm going to ask Mei and the rest if they've bought the frame. If not we'll go to Ikea and buy one? Because there are very few pieces left. Can complete.\n",
            "\n",
            "******************************\n",
            "Input_sentence: But cun lah... go next wk? Act where u wanna go?\n",
            "Predicted_sentence: Cat wan t wat wachandou want but wangout wat go go go wangowat cherch chawat go wau watrowat wangowan wangout gout want gou But wat wan go be go wat gou wanch gou goint ware ch gowat want bur ck in Bu\n",
            "Input Sentence: But cun lah... go next wk? Act where u wanna go?\n",
            "Predicted Sentence: Cat wan t wat wachandou want but wangout wat go go go wangowat cherch chawat go wau watrowat wangowan wangout gout want gou But wat wan go be go wat gou wanch gou goint ware ch gowat want bur ck in Bu\n",
            "Original English sentence: But please come. Are you going next week? Ask you where you want to go.\n",
            "\n",
            "******************************\n",
            "Input_sentence: ok!\n",
            "Predicted_sentence: I athe athe athe athe athe athe athe athe athe athe athe ayou athe athe athe athe at athe athe athe athe athe athe athe athe the athe the the athe athe athe athe the athe athek at athe athe athe athe \n",
            "Input Sentence: ok!\n",
            "Predicted Sentence: I athe athe athe athe athe athe athe athe athe athe athe ayou athe athe athe athe at athe athe athe athe athe athe athe athe the athe the the athe athe athe athe the athe athek at athe athe athe athe \n",
            "Original English sentence: Ok!\n",
            "\n",
            "******************************\n",
            "Input_sentence: So where n wat time u wan meet?\n",
            "Predicted_sentence: Se whe whe wat whan whe whe whe whe whe whawat whayoe what n whe what whe who whe whe what t yo whant wawhet nt what n whe what t whe t what t nt wat t t whe wan t whe whe me whe whe what what what me\n",
            "Input Sentence: So where n wat time u wan meet?\n",
            "Predicted Sentence: Se whe whe wat whan whe whe whe whe whe whawat whayoe what n whe what whe who whe whe what t yo whant wawhet nt what n whe what t whe t what t nt wat t t whe wan t whe whe me whe whe what what what me\n",
            "Original English sentence: So where and what time do you want to meet?\n",
            "\n",
            "******************************\n",
            "Input_sentence: You want a not? I will go buy for you... I reached orchard already\n",
            "Predicted_sentence: Doutou I me you anou al at re ano yo anou balreacallll you yotoupin al al gou I y fit anout re and yo ano reanou reano you you you yochant I ry you antillre yout anoread wad allll wat me reanoud bal y\n",
            "Input Sentence: You want a not? I will go buy for you... I reached orchard already\n",
            "Predicted Sentence: Doutou I me you anou al at re ano yo anou balreacallll you yotoupin al al gou I y fit anout re and yo ano reanou reano you you you yochant I ry you antillre yout anoread wad allll wat me reanoud bal y\n",
            "Original English sentence: You want or not? I will go to buy for you. I reached Orchard already.\n",
            "\n",
            "******************************\n",
            "Input_sentence: Hi, u male\n",
            "Predicted_sentence: Hing you you you you you you you t?\n",
            "\n",
            "Input Sentence: Hi, u male\n",
            "Predicted Sentence: Hing you you you you you you you t?\n",
            "\n",
            "Original English sentence: Hi, are you male?\n",
            "\n",
            "******************************\n",
            "Input_sentence: Where are you\n",
            "Predicted_sentence: Whe you you yowhe you you you you are you you are you you you you are you you are you you you you are you are you you you you are you you are you you you you you are you yowhe are you are you you you \n",
            "Input Sentence: Where are you\n",
            "Predicted Sentence: Whe you you yowhe you you you you are you you are you you you you are you you are you you you you are you are you you you you are you you are you you you you you are you yowhe are you are you you you \n",
            "Original English sentence: Where are you?\n",
            "\n",
            "******************************\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}