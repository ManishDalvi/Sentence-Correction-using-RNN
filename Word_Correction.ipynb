{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w6QSvoq2wWc9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, LSTM\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5atL8WoHax1i",
    "outputId": "8bbc7caf-0e1d-49f1-a5e0-31642987973c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gzl8wqRya8e5"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Novel_dataset_errors_train_3.csv\" \"/content/\"\n",
    "!cp \"/content/drive/MyDrive/Novel_dataset_errors_test_3.csv\" \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "EDJOwl1zw3aG",
    "outputId": "44f7c234-b171-452c-973d-615791e8364b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conteted fellows satiVsfied witrh their positi...</td>\n",
       "      <td>contented fellows satisfied with their positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at hte raPe of twentyseven miles a qday that t...</td>\n",
       "      <td>at the rate of twentyseven miles a day that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLwUCESTER</td>\n",
       "      <td>GLOUCESTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yas already full ou peNple There were people n...</td>\n",
       "      <td>was already full of people There were people n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feet</td>\n",
       "      <td>feet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input                                             target\n",
       "0  conteted fellows satiVsfied witrh their positi...  contented fellows satisfied with their positio...\n",
       "1  at hte raPe of twentyseven miles a qday that t...  at the rate of twentyseven miles a day that th...\n",
       "2                                         GLwUCESTER                                         GLOUCESTER\n",
       "3  yas already full ou peNple There were people n...  was already full of people There were people n...\n",
       "4                                               feet                                               feet"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Novel_dataset_errors_train_3.csv')\n",
    "test = pd.read_csv('Novel_dataset_errors_test_3.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3F2ltCutg5X",
    "outputId": "658114b9-45ca-4753-f414-7e5c6196cc5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "382072it [00:31, 12112.54it/s]\n"
     ]
    }
   ],
   "source": [
    "input_words = dict()\n",
    "\n",
    "for i, row in tqdm(train.iterrows()):\n",
    "    input_sentence = row['input']\n",
    "    target_sentence = row['target']\n",
    "    input_sentence_split = input_sentence.split(\" \")\n",
    "    target_sentence_split = target_sentence.split(\" \")\n",
    "\n",
    "    for i in range(len(input_sentence_split)):\n",
    "        if input_sentence_split[i] not in input_words:\n",
    "            input_words[input_sentence_split[i]] = target_sentence_split[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzaDoQ5P_YDr",
    "outputId": "2769d86b-c7d1-423e-aef8-d1d5eb217bb3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "965it [00:00, 11931.30it/s]\n"
     ]
    }
   ],
   "source": [
    "input_words_test = dict()\n",
    "\n",
    "for i, row in tqdm(test.iterrows()):\n",
    "    input_sentence = row['input']\n",
    "    target_sentence = row['target']\n",
    "    input_sentence_split = input_sentence.split(\" \")\n",
    "    target_sentence_split = target_sentence.split(\" \")\n",
    "\n",
    "    for i in range(len(input_sentence_split)):\n",
    "        if input_sentence_split[i] not in input_words_test:\n",
    "            input_words_test[input_sentence_split[i]] = target_sentence_split[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nYe6aObaAu5p"
   },
   "outputs": [],
   "source": [
    "input_words_list = []\n",
    "target_words_list = []\n",
    "input_words_list_test = []\n",
    "target_words_list_test = []\n",
    "\n",
    "for k,v in input_words.items():\n",
    "  input_words_list.append(k)\n",
    "  target_words_list.append(v)\n",
    "\n",
    "for k,v in input_words_test.items():\n",
    "  input_words_list_test.append(k)\n",
    "  target_words_list_test.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "02o0S4RZ_LE9"
   },
   "outputs": [],
   "source": [
    "train_words = pd.DataFrame({\n",
    "    'input':input_words_list,\n",
    "    'target':target_words_list\n",
    "})\n",
    "\n",
    "test_words = pd.DataFrame({\n",
    "    'input':input_words_list_test,\n",
    "    'target':target_words_list_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "sUoq7gppBLIv",
    "outputId": "aa04ae54-3184-48e7-d454-e04a048838b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conteted</td>\n",
       "      <td>contented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fellows</td>\n",
       "      <td>fellows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satiVsfied</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>witrh</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>their</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260508</th>\n",
       "      <td>tuYgged</td>\n",
       "      <td>tugged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260509</th>\n",
       "      <td>mighV</td>\n",
       "      <td>might</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260510</th>\n",
       "      <td>inOrigues</td>\n",
       "      <td>intrigues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260511</th>\n",
       "      <td>mmking</td>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260512</th>\n",
       "      <td>accompaniez</td>\n",
       "      <td>accompanied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              input       target\n",
       "0          conteted    contented\n",
       "1           fellows      fellows\n",
       "2        satiVsfied    satisfied\n",
       "3             witrh         with\n",
       "4             their        their\n",
       "...             ...          ...\n",
       "260508      tuYgged       tugged\n",
       "260509        mighV        might\n",
       "260510    inOrigues    intrigues\n",
       "260511       mmking       making\n",
       "260512  accompaniez  accompanied\n",
       "\n",
       "[260513 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7rdfmIke_ju4"
   },
   "outputs": [],
   "source": [
    "train = train_words\n",
    "test = test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqnRGnG88LYy",
    "outputId": "24ae2d8b-7232-4133-c5f1-e530aad5a4a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', ' ']\n"
     ]
    }
   ],
   "source": [
    "required_chars = []\n",
    "for char in string.printable:\n",
    "  if ord(char) > 31 and ord(char) < 126:\n",
    "    required_chars.append(char)\n",
    "\n",
    "\n",
    "print(len(required_chars))\n",
    "print(required_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xWM0cCmi7s5D"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of chars and index value from 1. 0 is reserved for padding by the tokenizer.\n",
    "vocabulary = dict()\n",
    "for i in range(len(required_chars)):\n",
    "  vocabulary[required_chars[i]] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WgItyynh7uWb"
   },
   "outputs": [],
   "source": [
    "# Use \\t as Start of Sentence and \\n as End of Sentence\n",
    "vocabulary['\\n'] = 95\n",
    "vocabulary['\\t'] = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BrFuNLIs2owY"
   },
   "outputs": [],
   "source": [
    "# Adding the \\t and \\n as part of start and end of sentence\n",
    "train['target_ip'] = '\\t' + train['target'].astype(str)\n",
    "train['target_op'] =  train['target'].astype(str) + '\\n'\n",
    "\n",
    "test['target_ip'] = '\\t' + test['target'].astype(str)\n",
    "test['target_op'] =  test['target'].astype(str) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aG58E_dY3JaN"
   },
   "outputs": [],
   "source": [
    "train = train.drop(['target'], axis=1)\n",
    "test = test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pn9P1Pl52rMl",
    "outputId": "c7fa77cf-790f-4ef6-aad4-2377db41c2bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target_ip</th>\n",
       "      <th>target_op</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conteted</td>\n",
       "      <td>\\tcontented</td>\n",
       "      <td>contented\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fellows</td>\n",
       "      <td>\\tfellows</td>\n",
       "      <td>fellows\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satiVsfied</td>\n",
       "      <td>\\tsatisfied</td>\n",
       "      <td>satisfied\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>witrh</td>\n",
       "      <td>\\twith</td>\n",
       "      <td>with\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>their</td>\n",
       "      <td>\\ttheir</td>\n",
       "      <td>their\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        input    target_ip    target_op\n",
       "0    conteted  \\tcontented  contented\\n\n",
       "1     fellows    \\tfellows    fellows\\n\n",
       "2  satiVsfied  \\tsatisfied  satisfied\\n\n",
       "3       witrh       \\twith       with\\n\n",
       "4       their      \\ttheir      their\\n"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dccV3FWe3IbF"
   },
   "outputs": [],
   "source": [
    "train.iloc[0]['target_ip']= str(train.iloc[0]['target_ip'])+'\\n'\n",
    "train.iloc[0]['target_op']= str(train.iloc[0]['target_op'])+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93Ub9wTxyymO",
    "outputId": "da89fdd8-0acb-4869-d0b5-734b705f947b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# Calculating the maximum length of among all the sentences which will be useful for padding.\n",
    "max_length_encoder = train['input'].map(len).max()\n",
    "\n",
    "print(max_length_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1M6VC2ixr6J",
    "outputId": "ee6b8c7e-c4ec-4a41-cb60-e0660f21407e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "max_length_decoder = max( train['target_ip'].map(len).max(), train['target_op'].map(len).max())\n",
    "print(max_length_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "brw3mDkGxemO"
   },
   "outputs": [],
   "source": [
    "# Tokenizer for the raw input and target output\n",
    "tokenizer_raw_ip = Tokenizer(\n",
    "    char_level=True,\n",
    "    lower=False,\n",
    "    filters=None\n",
    ")\n",
    "\n",
    "tokenizer_target_ip = Tokenizer(\n",
    "    char_level=True,\n",
    "    lower=False,\n",
    "    filters=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B6VhrB0BxkS_"
   },
   "outputs": [],
   "source": [
    "tokenizer_raw_ip.fit_on_texts(train['input'].values)\n",
    "tokenizer_target_ip.fit_on_texts(train['target_ip'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_OMsgwWd72wz"
   },
   "outputs": [],
   "source": [
    "# Replacing the vocabulary of the trained index to a vocabulary mentioned in the research paper\n",
    "tokenizer_target_ip.word_index = vocabulary\n",
    "tokenizer_raw_ip.word_index = vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCobtx0TDkqS",
    "outputId": "0f09b95e-8ce0-404c-9205-a7d867cf1716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "target_vocab_size=len(tokenizer_target_ip.word_index.keys())\n",
    "print(target_vocab_size)\n",
    "input_vocab_size=len(tokenizer_raw_ip.word_index.keys())\n",
    "print(input_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NbS-j6zFDZTk"
   },
   "outputs": [],
   "source": [
    "# Encoder class with Embedding layer and LSTM layer.\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, enc_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.enc_units= enc_units\n",
    "        self.lstm_output = 0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Embedding_Layer_Encoder\")\n",
    "        self.lstm_1 = LSTM(self.enc_units, recurrent_dropout=0.2, return_state=True, return_sequences=True, name=\"Encoder_LSTM_1\")\n",
    "        self.lstm_2 = LSTM(self.enc_units, recurrent_dropout=0.2, return_state=True, return_sequences=True, name=\"Encoder_LSTM_2\")\n",
    "        \n",
    "    def call(self, input_sentances, training=True):\n",
    "        # input_embedded = self.embedding(input_sentances)\n",
    "        self.lstm_output,_,_ = self.lstm_1(input_sentances)\n",
    "        self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.lstm_2(self.lstm_output)\n",
    "\n",
    "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
    "\n",
    "    def get_states(self):\n",
    "        return self.lstm_state_h,self.lstm_state_c\n",
    "    \n",
    "# Decoder class with embedding and LSTM layer.    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length, dec_units):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\n",
    "        # we are using embedding_matrix and not training the embedding layer\n",
    "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, mask_zero=True, name=\"Embedding_Layer_Decoder\",)\n",
    "        self.lstm = LSTM(self.dec_units,  dropout=0.2, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "    \n",
    "    def call(self, target_sentences, state_h, state_c):\n",
    "        # target_embedded           = self.embedding(target_sentences)\n",
    "        lstm_output, _,_        = self.lstm(target_sentences, initial_state=[state_h, state_c])\n",
    "        return lstm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bdPsfdMTDcUa"
   },
   "outputs": [],
   "source": [
    "# Creating a data pipeline\n",
    "class Dataset:\n",
    "    def __init__(self, data, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder,max_length_decoder):\n",
    "        self.encoder_inps = data['input'].values\n",
    "        self.decoder_inps = data['target_ip'].values\n",
    "        self.decoder_outs = data['target_op'].values\n",
    "        self.tokenizer_target_ip = tokenizer_target_ip\n",
    "        self.tokenizer_raw_ip = tokenizer_raw_ip\n",
    "        self.max_length_encoder = max_length_encoder\n",
    "        self.max_length_decoder = max_length_decoder\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tokenizer_raw_ip.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tokenizer_target_ip.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_length_encoder, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_length_decoder, dtype='int32', padding='post')\n",
    "\n",
    "        self.encoder_seq = tf.keras.utils.to_categorical(self.encoder_seq, num_classes=len(tokenizer_raw_ip.word_index.keys())+1)\n",
    "        self.decoder_inp_seq = tf.keras.utils.to_categorical(self.decoder_inp_seq, num_classes=len(tokenizer_target_ip.word_index.keys())+1)\n",
    "        self.decoder_out_seq = tf.keras.utils.to_categorical(self.decoder_out_seq, num_classes=len(tokenizer_target_ip.word_index.keys())+1)\n",
    "\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloder(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "            \n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9dmaj0EADi5a"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)\n",
    "test_dataset  = Dataset(test, tokenizer_raw_ip, tokenizer_target_ip, max_length_encoder, max_length_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ti9VvFy7YE8a",
    "outputId": "c19439aa-0070-4b25-b10a-884546987216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 40, 97) (1024, 41, 97) (1024, 41, 97)\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=128)\n",
    "\n",
    "print(train_dataloader[1][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TSWOLZxfES-T"
   },
   "outputs": [],
   "source": [
    "# Model 1 - 1 layer LSTM model for each encoder and decoder\n",
    "class Model1(Model):\n",
    "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\n",
    "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
    "        self.encoder = Encoder(vocab_size=input_vocab_size+1, embedding_dim=30, input_length=encoder_inputs_length, enc_units=512)\n",
    "        self.decoder = Decoder(vocab_size=target_vocab_size+1, embedding_dim=30, input_length=decoder_inputs_length, dec_units=512)\n",
    "        self.dense   = Dense(output_vocab_size+1, activation='softmax')\n",
    "        \n",
    "    def call(self, data):\n",
    "        input,output = data[0], data[1]\n",
    "        encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
    "        decoder_output                       = self.decoder(output, encoder_h, encoder_c)\n",
    "        output                               = self.dense(decoder_output)\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "JdhEtfL4mpIo"
   },
   "outputs": [],
   "source": [
    "# Reduce learning rate based on the validation loss\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.99, verbose=1, mode='min', min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "h54iCsvQElOp"
   },
   "outputs": [],
   "source": [
    "model  = Model1(encoder_inputs_length=max_length_encoder,decoder_inputs_length=max_length_decoder,output_vocab_size=target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pJCvd660V1we"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/content/drive/MyDrive/my_model_spell/model_1'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Bcix47d-L2Ap"
   },
   "outputs": [],
   "source": [
    "# Using Adam and Gradient clipping to prevent gradient explosion as mentioned in the research paper\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=test.shape[0]//128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aV6gpE1iE5a7",
    "outputId": "6fe42614-2ba4-4f3b-9ea5-6d90194424ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer Encoder_LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer Encoder_LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/200\n",
      "254/254 [==============================] - 130s 494ms/step - loss: 0.7241 - accuracy: 0.8241 - val_loss: 0.3518 - val_accuracy: 0.8936\n",
      "Epoch 2/200\n",
      "254/254 [==============================] - 123s 482ms/step - loss: 0.4148 - accuracy: 0.8756 - val_loss: 0.3086 - val_accuracy: 0.9069\n",
      "Epoch 3/200\n",
      "254/254 [==============================] - 122s 481ms/step - loss: 0.5998 - accuracy: 0.8568 - val_loss: 0.3309 - val_accuracy: 0.9020\n",
      "Epoch 4/200\n",
      "254/254 [==============================] - 123s 482ms/step - loss: 0.3915 - accuracy: 0.8852 - val_loss: 0.2987 - val_accuracy: 0.9109\n",
      "Epoch 5/200\n",
      "254/254 [==============================] - 123s 482ms/step - loss: 0.3680 - accuracy: 0.8907 - val_loss: 0.2823 - val_accuracy: 0.9147\n",
      "Epoch 6/200\n",
      "254/254 [==============================] - 123s 485ms/step - loss: 0.3548 - accuracy: 0.8944 - val_loss: 0.2668 - val_accuracy: 0.9212\n",
      "Epoch 7/200\n",
      "254/254 [==============================] - 122s 481ms/step - loss: 0.3418 - accuracy: 0.8989 - val_loss: 0.2481 - val_accuracy: 0.9267\n",
      "Epoch 8/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.3265 - accuracy: 0.9042 - val_loss: 0.2346 - val_accuracy: 0.9309\n",
      "Epoch 9/200\n",
      "254/254 [==============================] - 124s 488ms/step - loss: 0.3122 - accuracy: 0.9087 - val_loss: 0.2216 - val_accuracy: 0.9359\n",
      "Epoch 10/200\n",
      "254/254 [==============================] - 123s 484ms/step - loss: 0.3031 - accuracy: 0.9116 - val_loss: 0.2148 - val_accuracy: 0.9379\n",
      "Epoch 11/200\n",
      "254/254 [==============================] - 123s 483ms/step - loss: 0.2953 - accuracy: 0.9138 - val_loss: 0.2058 - val_accuracy: 0.9399\n",
      "Epoch 12/200\n",
      "254/254 [==============================] - 122s 482ms/step - loss: 0.2886 - accuracy: 0.9159 - val_loss: 0.2004 - val_accuracy: 0.9417\n",
      "Epoch 13/200\n",
      "254/254 [==============================] - 125s 491ms/step - loss: 0.2808 - accuracy: 0.9182 - val_loss: 0.1921 - val_accuracy: 0.9441\n",
      "Epoch 14/200\n",
      "254/254 [==============================] - 124s 489ms/step - loss: 0.2730 - accuracy: 0.9204 - val_loss: 0.1843 - val_accuracy: 0.9467\n",
      "Epoch 15/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.2640 - accuracy: 0.9232 - val_loss: 0.1758 - val_accuracy: 0.9495\n",
      "Epoch 16/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.2550 - accuracy: 0.9257 - val_loss: 0.1660 - val_accuracy: 0.9519\n",
      "Epoch 17/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.2452 - accuracy: 0.9286 - val_loss: 0.1571 - val_accuracy: 0.9557\n",
      "Epoch 18/200\n",
      "254/254 [==============================] - 122s 480ms/step - loss: 0.2374 - accuracy: 0.9310 - val_loss: 0.1489 - val_accuracy: 0.9584\n",
      "Epoch 19/200\n",
      "254/254 [==============================] - 125s 490ms/step - loss: 0.2295 - accuracy: 0.9333 - val_loss: 0.1456 - val_accuracy: 0.9589\n",
      "Epoch 20/200\n",
      "254/254 [==============================] - 124s 488ms/step - loss: 0.2243 - accuracy: 0.9349 - val_loss: 0.1386 - val_accuracy: 0.9604\n",
      "Epoch 21/200\n",
      "254/254 [==============================] - 124s 489ms/step - loss: 0.2193 - accuracy: 0.9363 - val_loss: 0.1320 - val_accuracy: 0.9626\n",
      "Epoch 22/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.2130 - accuracy: 0.9381 - val_loss: 0.1286 - val_accuracy: 0.9633\n",
      "Epoch 23/200\n",
      "254/254 [==============================] - 124s 488ms/step - loss: 0.2089 - accuracy: 0.9393 - val_loss: 0.1256 - val_accuracy: 0.9641\n",
      "Epoch 24/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.2027 - accuracy: 0.9412 - val_loss: 0.1201 - val_accuracy: 0.9659\n",
      "Epoch 25/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.1991 - accuracy: 0.9422 - val_loss: 0.1173 - val_accuracy: 0.9672\n",
      "Epoch 26/200\n",
      "254/254 [==============================] - 124s 485ms/step - loss: 0.1946 - accuracy: 0.9435 - val_loss: 0.1139 - val_accuracy: 0.9674\n",
      "Epoch 27/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.1897 - accuracy: 0.9449 - val_loss: 0.1070 - val_accuracy: 0.9699\n",
      "Epoch 28/200\n",
      "254/254 [==============================] - 122s 481ms/step - loss: 0.1858 - accuracy: 0.9461 - val_loss: 0.1046 - val_accuracy: 0.9712\n",
      "Epoch 29/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.1816 - accuracy: 0.9473 - val_loss: 0.1015 - val_accuracy: 0.9715\n",
      "Epoch 30/200\n",
      "254/254 [==============================] - 122s 479ms/step - loss: 0.1773 - accuracy: 0.9485 - val_loss: 0.1011 - val_accuracy: 0.9720\n",
      "Epoch 31/200\n",
      "254/254 [==============================] - 124s 488ms/step - loss: 0.1744 - accuracy: 0.9493 - val_loss: 0.0965 - val_accuracy: 0.9733\n",
      "Epoch 32/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.1685 - accuracy: 0.9510 - val_loss: 0.0929 - val_accuracy: 0.9742\n",
      "Epoch 33/200\n",
      "254/254 [==============================] - 123s 484ms/step - loss: 0.1656 - accuracy: 0.9519 - val_loss: 0.0906 - val_accuracy: 0.9749\n",
      "Epoch 34/200\n",
      "254/254 [==============================] - 124s 489ms/step - loss: 0.1632 - accuracy: 0.9525 - val_loss: 0.0869 - val_accuracy: 0.9765\n",
      "Epoch 35/200\n",
      "254/254 [==============================] - 124s 489ms/step - loss: 0.1585 - accuracy: 0.9540 - val_loss: 0.0872 - val_accuracy: 0.9758\n",
      "Epoch 36/200\n",
      "254/254 [==============================] - 124s 486ms/step - loss: 0.1567 - accuracy: 0.9545 - val_loss: 0.0859 - val_accuracy: 0.9757\n",
      "Epoch 37/200\n",
      "254/254 [==============================] - 124s 489ms/step - loss: 0.1542 - accuracy: 0.9551 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
      "Epoch 38/200\n",
      "254/254 [==============================] - 125s 490ms/step - loss: 0.1512 - accuracy: 0.9562 - val_loss: 0.0793 - val_accuracy: 0.9785\n",
      "Epoch 39/200\n",
      "254/254 [==============================] - 125s 493ms/step - loss: 0.1471 - accuracy: 0.9574 - val_loss: 0.0793 - val_accuracy: 0.9783\n",
      "Epoch 40/200\n",
      "254/254 [==============================] - 124s 487ms/step - loss: 0.1462 - accuracy: 0.9578 - val_loss: 0.0769 - val_accuracy: 0.9788\n",
      "Epoch 41/200\n",
      " 61/254 [======>.......................] - ETA: 1:34 - loss: 0.1423 - accuracy: 0.9590"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9b317731876c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=200,  validation_data=test_dataloader, validation_steps=valid_steps, callbacks=[reduce_lr, model_checkpoint_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tJ8psjoiyTHu",
    "outputId": "0708ee30-03fa-43e8-ff26-a803cb468c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 161s 615ms/step - loss: 0.1342 - accuracy: 0.9614 - val_loss: 0.0674 - val_accuracy: 0.9814\n",
      "Epoch 2/200\n",
      "254/254 [==============================] - 156s 613ms/step - loss: 0.1287 - accuracy: 0.9630 - val_loss: 0.0656 - val_accuracy: 0.9822\n",
      "Epoch 3/200\n",
      "254/254 [==============================] - 155s 610ms/step - loss: 0.1241 - accuracy: 0.9644 - val_loss: 0.0638 - val_accuracy: 0.9827\n",
      "Epoch 4/200\n",
      "254/254 [==============================] - 156s 615ms/step - loss: 0.1225 - accuracy: 0.9648 - val_loss: 0.0620 - val_accuracy: 0.9834\n",
      "Epoch 5/200\n",
      "254/254 [==============================] - 156s 613ms/step - loss: 0.1198 - accuracy: 0.9655 - val_loss: 0.0613 - val_accuracy: 0.9833\n",
      "Epoch 6/200\n",
      "254/254 [==============================] - 156s 614ms/step - loss: 0.1180 - accuracy: 0.9661 - val_loss: 0.0597 - val_accuracy: 0.9841\n",
      "Epoch 7/200\n",
      "254/254 [==============================] - 155s 612ms/step - loss: 0.1167 - accuracy: 0.9664 - val_loss: 0.0577 - val_accuracy: 0.9847\n",
      "Epoch 8/200\n",
      "254/254 [==============================] - 156s 613ms/step - loss: 0.1142 - accuracy: 0.9671 - val_loss: 0.0553 - val_accuracy: 0.9853\n",
      "Epoch 9/200\n",
      "254/254 [==============================] - 155s 610ms/step - loss: 0.1105 - accuracy: 0.9681 - val_loss: 0.0537 - val_accuracy: 0.9856\n",
      "Epoch 10/200\n",
      "254/254 [==============================] - 155s 609ms/step - loss: 0.1094 - accuracy: 0.9684 - val_loss: 0.0525 - val_accuracy: 0.9859\n",
      "Epoch 11/200\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.1064 - accuracy: 0.9693 - val_loss: 0.0510 - val_accuracy: 0.9865\n",
      "Epoch 12/200\n",
      "254/254 [==============================] - 156s 614ms/step - loss: 0.1040 - accuracy: 0.9700 - val_loss: 0.0496 - val_accuracy: 0.9868\n",
      "Epoch 13/200\n",
      "254/254 [==============================] - 156s 614ms/step - loss: 0.1023 - accuracy: 0.9705 - val_loss: 0.0488 - val_accuracy: 0.9869\n",
      "Epoch 14/200\n",
      "254/254 [==============================] - 157s 616ms/step - loss: 0.1016 - accuracy: 0.9707 - val_loss: 0.0470 - val_accuracy: 0.9877\n",
      "Epoch 15/200\n",
      "254/254 [==============================] - 155s 610ms/step - loss: 0.0988 - accuracy: 0.9715 - val_loss: 0.0461 - val_accuracy: 0.9877\n",
      "Epoch 16/200\n",
      "254/254 [==============================] - 155s 611ms/step - loss: 0.0972 - accuracy: 0.9719 - val_loss: 0.0454 - val_accuracy: 0.9877\n",
      "Epoch 17/200\n",
      "254/254 [==============================] - 154s 607ms/step - loss: 0.0962 - accuracy: 0.9722 - val_loss: 0.0447 - val_accuracy: 0.9879\n",
      "Epoch 18/200\n",
      "254/254 [==============================] - 156s 614ms/step - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.0436 - val_accuracy: 0.9884\n",
      "Epoch 19/200\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0928 - accuracy: 0.9732 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 20/200\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0919 - accuracy: 0.9734 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
      "Epoch 21/200\n",
      " 17/254 [=>............................] - ETA: 2:25 - loss: 0.0869 - accuracy: 0.9748"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9b317731876c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=200,  validation_data=test_dataloader, validation_steps=valid_steps, callbacks=[reduce_lr, model_checkpoint_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxYUVbPJ-pjb",
    "outputId": "497a3daa-a400-4f76-c807-b686976fe0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 157s 619ms/step - loss: 0.0873 - accuracy: 0.9747 - val_loss: 0.0398 - val_accuracy: 0.9895\n",
      "Epoch 4/50\n",
      "254/254 [==============================] - 160s 628ms/step - loss: 0.0863 - accuracy: 0.9750 - val_loss: 0.0394 - val_accuracy: 0.9895\n",
      "Epoch 5/50\n",
      "254/254 [==============================] - 159s 623ms/step - loss: 0.0857 - accuracy: 0.9752 - val_loss: 0.0384 - val_accuracy: 0.9898\n",
      "Epoch 6/50\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0839 - accuracy: 0.9758 - val_loss: 0.0378 - val_accuracy: 0.9898\n",
      "Epoch 7/50\n",
      "254/254 [==============================] - 158s 621ms/step - loss: 0.0822 - accuracy: 0.9763 - val_loss: 0.0372 - val_accuracy: 0.9901\n",
      "Epoch 8/50\n",
      "254/254 [==============================] - 156s 616ms/step - loss: 0.0812 - accuracy: 0.9765 - val_loss: 0.0368 - val_accuracy: 0.9902\n",
      "Epoch 9/50\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0806 - accuracy: 0.9767 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
      "Epoch 10/50\n",
      "254/254 [==============================] - 159s 624ms/step - loss: 0.0795 - accuracy: 0.9770 - val_loss: 0.0356 - val_accuracy: 0.9905\n",
      "Epoch 11/50\n",
      "254/254 [==============================] - 157s 616ms/step - loss: 0.0788 - accuracy: 0.9773 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 12/50\n",
      "254/254 [==============================] - 157s 619ms/step - loss: 0.0770 - accuracy: 0.9777 - val_loss: 0.0349 - val_accuracy: 0.9908\n",
      "Epoch 13/50\n",
      "254/254 [==============================] - 158s 620ms/step - loss: 0.0763 - accuracy: 0.9779 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
      "Epoch 14/50\n",
      "254/254 [==============================] - 159s 624ms/step - loss: 0.0742 - accuracy: 0.9785 - val_loss: 0.0337 - val_accuracy: 0.9910\n",
      "Epoch 15/50\n",
      "254/254 [==============================] - 158s 620ms/step - loss: 0.0734 - accuracy: 0.9788 - val_loss: 0.0330 - val_accuracy: 0.9912\n",
      "Epoch 16/50\n",
      "254/254 [==============================] - 159s 625ms/step - loss: 0.0730 - accuracy: 0.9789 - val_loss: 0.0326 - val_accuracy: 0.9912\n",
      "Epoch 17/50\n",
      "254/254 [==============================] - 159s 624ms/step - loss: 0.0720 - accuracy: 0.9792 - val_loss: 0.0327 - val_accuracy: 0.9914\n",
      "Epoch 18/50\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0702 - accuracy: 0.9797 - val_loss: 0.0319 - val_accuracy: 0.9915\n",
      "Epoch 19/50\n",
      "254/254 [==============================] - 157s 617ms/step - loss: 0.0695 - accuracy: 0.9799 - val_loss: 0.0317 - val_accuracy: 0.9916\n",
      "Epoch 20/50\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0687 - accuracy: 0.9801 - val_loss: 0.0311 - val_accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "254/254 [==============================] - 159s 624ms/step - loss: 0.0679 - accuracy: 0.9804 - val_loss: 0.0311 - val_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0666 - accuracy: 0.9808 - val_loss: 0.0305 - val_accuracy: 0.9919\n",
      "Epoch 23/50\n",
      "254/254 [==============================] - 157s 619ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 0.0298 - val_accuracy: 0.9920\n",
      "Epoch 24/50\n",
      "254/254 [==============================] - 158s 621ms/step - loss: 0.0656 - accuracy: 0.9811 - val_loss: 0.0295 - val_accuracy: 0.9922\n",
      "Epoch 25/50\n",
      "254/254 [==============================] - 158s 620ms/step - loss: 0.0640 - accuracy: 0.9816 - val_loss: 0.0290 - val_accuracy: 0.9923\n",
      "Epoch 26/50\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 0.0287 - val_accuracy: 0.9924\n",
      "Epoch 27/50\n",
      "254/254 [==============================] - 158s 621ms/step - loss: 0.0627 - accuracy: 0.9819 - val_loss: 0.0283 - val_accuracy: 0.9925\n",
      "Epoch 28/50\n",
      "254/254 [==============================] - 159s 626ms/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.0278 - val_accuracy: 0.9925\n",
      "Epoch 29/50\n",
      "254/254 [==============================] - 159s 626ms/step - loss: 0.0609 - accuracy: 0.9824 - val_loss: 0.0276 - val_accuracy: 0.9926\n",
      "Epoch 30/50\n",
      "254/254 [==============================] - 160s 629ms/step - loss: 0.0606 - accuracy: 0.9825 - val_loss: 0.0273 - val_accuracy: 0.9927\n",
      "Epoch 31/50\n",
      "254/254 [==============================] - 159s 627ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.0273 - val_accuracy: 0.9927\n",
      "Epoch 32/50\n",
      "254/254 [==============================] - 156s 614ms/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.0266 - val_accuracy: 0.9929\n",
      "Epoch 33/50\n",
      "254/254 [==============================] - 158s 619ms/step - loss: 0.0587 - accuracy: 0.9830 - val_loss: 0.0263 - val_accuracy: 0.9931\n",
      "Epoch 34/50\n",
      "254/254 [==============================] - 156s 615ms/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 0.0264 - val_accuracy: 0.9929\n",
      "Epoch 35/50\n",
      "254/254 [==============================] - 157s 619ms/step - loss: 0.0576 - accuracy: 0.9833 - val_loss: 0.0256 - val_accuracy: 0.9931\n",
      "Epoch 36/50\n",
      "254/254 [==============================] - 158s 620ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.0256 - val_accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0557 - accuracy: 0.9839 - val_loss: 0.0253 - val_accuracy: 0.9932\n",
      "Epoch 38/50\n",
      "254/254 [==============================] - 158s 620ms/step - loss: 0.0552 - accuracy: 0.9840 - val_loss: 0.0252 - val_accuracy: 0.9933\n",
      "Epoch 39/50\n",
      "254/254 [==============================] - 158s 622ms/step - loss: 0.0546 - accuracy: 0.9842 - val_loss: 0.0248 - val_accuracy: 0.9932\n",
      "Epoch 40/50\n",
      "254/254 [==============================] - 157s 617ms/step - loss: 0.0534 - accuracy: 0.9846 - val_loss: 0.0248 - val_accuracy: 0.9934\n",
      "Epoch 41/50\n",
      "254/254 [==============================] - 158s 621ms/step - loss: 0.0524 - accuracy: 0.9849 - val_loss: 0.0245 - val_accuracy: 0.9935\n",
      "Epoch 42/50\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0523 - accuracy: 0.9849 - val_loss: 0.0243 - val_accuracy: 0.9935\n",
      "Epoch 43/50\n",
      "254/254 [==============================] - 157s 618ms/step - loss: 0.0517 - accuracy: 0.9850 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
      "Epoch 44/50\n",
      "254/254 [==============================] - 159s 625ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0238 - val_accuracy: 0.9935\n",
      "Epoch 45/50\n",
      "254/254 [==============================] - 160s 628ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.0238 - val_accuracy: 0.9936\n",
      "Epoch 46/50\n",
      "254/254 [==============================] - 159s 625ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.0237 - val_accuracy: 0.9936\n",
      "Epoch 47/50\n",
      "254/254 [==============================] - 161s 632ms/step - loss: 0.0493 - accuracy: 0.9857 - val_loss: 0.0232 - val_accuracy: 0.9938\n",
      "Epoch 48/50\n",
      "121/254 [=============>................] - ETA: 1:22 - loss: 0.0492 - accuracy: 0.9857"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50,  validation_data=test_dataloader, validation_steps=valid_steps, callbacks=[reduce_lr, model_checkpoint_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "n3KeUQ22DeQA"
   },
   "outputs": [],
   "source": [
    "!cp '/content/drive/MyDrive/my_model_spell/model_2/checkpoint' \"/content/\"\n",
    "!cp '/content/drive/MyDrive/my_model_spell/model_2/model_2.data-00000-of-00001' \"/content/\"\n",
    "!cp '/content/drive/MyDrive/my_model_spell/model_2/model_2.index' \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3YU1I_PeuTu",
    "outputId": "64ca4a2f-6d74-4324-e6c4-bda6ae6f699e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f68d015c750>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f3mD2ytpkGS",
    "outputId": "3bae69e0-982b-4c28-c55c-1d8d9867d53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer Encoder_LSTM_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer Encoder_LSTM_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "32/32 [==============================] - 3s 52ms/step - loss: 0.0212 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023236896842718124, 0.9938250184059143]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaQQNo8EJD3h",
    "outputId": "03cb45ef-e920-43e8-feb8-8a5899a7ed52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss of the model 1 is: 0.0232\n",
      "The perplexity of the model 1 is: 1.0162110099886057\n"
     ]
    }
   ],
   "source": [
    "print(\"The validation loss of the model 1 is:\", 0.0232)\n",
    "print(\"The perplexity of the model 1 is:\", 2**(0.0232))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WYCJG2Ck8gz"
   },
   "source": [
    "#-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "B8S2iljez9AW"
   },
   "outputs": [],
   "source": [
    "start_index = tokenizer_target_ip.word_index['\\t']\n",
    "end_index = tokenizer_target_ip.word_index['\\n']\n",
    "DECODER_SEQ_LEN = max_length_decoder\n",
    "max_len = max_length_decoder\n",
    "\n",
    "\n",
    "def predict(input_sentence):\n",
    "  word_list = []\n",
    "  split_sentence = input_sentence.split(\" \")\n",
    "  for word in split_sentence:\n",
    "\n",
    "      encoder_seq = tokenizer_raw_ip.texts_to_sequences([word])\n",
    "\n",
    "      encoder_seq = pad_sequences(encoder_seq, maxlen=max_length_encoder, dtype='int32', padding='post')\n",
    "\n",
    "      encoder_seq = tf.keras.utils.to_categorical(encoder_seq, num_classes=len(tokenizer_raw_ip.word_index.keys())+1)\n",
    "\n",
    "      enc_output, enc_state_h, enc_state_c = model.layers[0](encoder_seq)\n",
    "\n",
    "      dec_input = np.zeros((1, 1, len(tokenizer_raw_ip.word_index.keys())+1))\n",
    "\n",
    "      dec_input[0, 0, tokenizer_target_ip.word_index['\\t']] = 1.\n",
    "\n",
    "      input_state = [enc_state_h, enc_state_c]\n",
    "\n",
    "      output_word = []\n",
    "\n",
    "      for i in range(DECODER_SEQ_LEN):\n",
    "          # cur_emb = model.layers[1].embedding(dec_input)\n",
    "\n",
    "          predicted_out, state_h, state_c = model.layers[1].lstm(dec_input, input_state)\n",
    "\n",
    "          dense_layer_out = model.layers[2](predicted_out)\n",
    "\n",
    "          input_state = [state_h, state_c]\n",
    "      \n",
    "          output_word_index = np.argmax(dense_layer_out)\n",
    "\n",
    "          # print(output_word_index)\n",
    "\n",
    "          for key, value in tokenizer_target_ip.word_index.items():\n",
    "\n",
    "            if output_word_index == value:\n",
    "                output_word.append(key)\n",
    "\n",
    "          dec_input = np.reshape(output_word_index, (1, 1))\n",
    "\n",
    "          dec_input = np.zeros((1, 1, len(tokenizer_raw_ip.word_index.keys())+1))\n",
    "\n",
    "          dec_input[0, 0, output_word_index] = 1.\n",
    "\n",
    "\n",
    "          if output_word_index == tokenizer_target_ip.word_index['\\n']:\n",
    "            break\n",
    "\n",
    "      word = \"\".join(output_word)\n",
    "      word_list.append(word)\n",
    "      # print(word_list)\n",
    "  sentence = ''.join(word_list)\n",
    "  sentence = sentence.replace(\"\\n\", \" \")\n",
    "  return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQdlkAgYz9AZ",
    "outputId": "8cf5d8cf-149b-4dba-d64d-221ed2326347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: yM hate to Marcius hwere I find him were it\n",
      "Predicted Sentence: My hate to Marcius where I find him were it \n",
      "Original English sentence: My hate to Marcius where I find him were it\n",
      "******************************\n",
      "Input Sentence: Petay Hhad Trepared many fine things he meant to say to the gentlemanin\n",
      "Predicted Sentence: Petya had reparted many fine things he meant to say to the gentlemaning \n",
      "Original English sentence: Petya had prepared many fine things he meant to say to the gentlemanin\n",
      "******************************\n",
      "Input Sentence: abGruptly\n",
      "Predicted Sentence: abroutely \n",
      "Original English sentence: abruptly\n",
      "******************************\n",
      "Input Sentence: mattedr acd Uto that I reply You are my best friend as you know but\n",
      "Predicted Sentence: matterd and to that I reply You are my best friend as you know but \n",
      "Original English sentence: matter and to that I reply You are my best friend as you know but\n",
      "******************************\n",
      "Input Sentence: But thee sworcs were drwan back from him and he was at once blindfolded\n",
      "Predicted Sentence: But thee sworces were drawn back from him and he was at once blindfolded \n",
      "Original English sentence: But the swords were drawn back from him and he was at once blindfolded\n",
      "******************************\n",
      "Input Sentence: in aher room crynig flike a child blowing her nose and sobbing Sonya\n",
      "Predicted Sentence: in her room crying like as child blowing her nose and sobbing Sonya \n",
      "Original English sentence: in her room crying like a child blowing her nose and sobbing Sonya\n",
      "******************************\n",
      "Input Sentence: lFdies aYd alZl these civilities said he aloud in Sonyas presence\n",
      "Predicted Sentence: ladies and all these civilities said he aloud in Sonyas presence \n",
      "Original English sentence: ladies and all these civilities said he aloud in Sonyas presence\n",
      "******************************\n",
      "Input Sentence: Cafrouse ful mePasure to her maidenhead\n",
      "Predicted Sentence: Carrouse full measure to her maidenedhand \n",
      "Original English sentence: Carouse full measure to her maidenhead\n",
      "******************************\n",
      "Input Sentence: Th wetaher was alreaQy growing wintry and morning frosts congealed an\n",
      "Predicted Sentence: The weather was already growing wintry and morning frosts congealed an \n",
      "Original English sentence: The weather was already growing wintry and morning frosts congealed an\n",
      "******************************\n",
      "Input Sentence: PAULINA\n",
      "Predicted Sentence: PAULINA \n",
      "Original English sentence: PAULINA\n",
      "******************************\n",
      "Input Sentence: caleche Vhe kne i was right in front\n",
      "Predicted Sentence: caleche he knew in was right in front \n",
      "Original English sentence: caleche She knew it was right in front\n",
      "******************************\n",
      "Input Sentence: erself n a whtie satin dressing gown embroidered with silver and with\n",
      "Predicted Sentence: eyrelf no as white stain dressing gown embroidered with silver and with \n",
      "Original English sentence: herself in a white satin dressing gown embroidered with silver and with\n",
      "******************************\n",
      "Input Sentence: Ee I wgll see the croUwn so foul misplaced\n",
      "Predicted Sentence: He I well see the crown so foul mispleced \n",
      "Original English sentence: Ere I will see the crown so foul misplaced\n",
      "******************************\n",
      "Input Sentence: Natasha understood taht btu simply because he thought it was all that\n",
      "Predicted Sentence: Natasha understood that but simply because he thought it was all that \n",
      "Original English sentence: Natasha understood that but simply because he thought it was all that\n",
      "******************************\n",
      "Input Sentence: T the demd bodies of ym queen and son\n",
      "Predicted Sentence: To the demdd bodies of my queen and son \n",
      "Original English sentence: To the dead bodies of my queen and son\n",
      "******************************\n",
      "Input Sentence: discovereXd the efficacy of poetry iR driving atay love\n",
      "Predicted Sentence: discovered the efficar off poetery is driving attay love \n",
      "Original English sentence: discovered the efficacy of poetry in driving away love\n",
      "******************************\n",
      "Input Sentence: AUFIDIUS\n",
      "Predicted Sentence: AUFIDIUS \n",
      "Original English sentence: AUFIDIUS\n",
      "******************************\n",
      "Input Sentence: To ese you are becoame sD penitent\n",
      "Predicted Sentence: To es you are became so penitent \n",
      "Original English sentence: To see you are become so penitent\n",
      "******************************\n",
      "Input Sentence: about Sergey Kuzmich tChat interestet Prince aVsili just then and Prince\n",
      "Predicted Sentence: about Sergey Kuzmich that interested Prince assili just then and Prince \n",
      "Original English sentence: about Sergey Kuzmich that interested Prince Vasili just then and Prince\n",
      "******************************\n",
      "Input Sentence: jo slave hnce\n",
      "Predicted Sentence: jo slave hince \n",
      "Original English sentence: So slave hence\n",
      "******************************\n",
      "Input Sentence: unpVeasantly and Le replied hastily\n",
      "Predicted Sentence: unpleasantly and Le replied hastily \n",
      "Original English sentence: unpleasantly and he replied hastily\n",
      "******************************\n",
      "Input Sentence: thta wal noq what made her unrecognizable she was unrecognizable at the\n",
      "Predicted Sentence: that wall not what made her unrecignizenle she was unrepigningleated at the \n",
      "Original English sentence: that was not what made her unrecognizable she was unrecognizable at the\n",
      "******************************\n",
      "Input Sentence: aborad werIe less variev than before and at home she had a mother and\n",
      "Predicted Sentence: abroad were less varvet thank before and at home she had as mother and \n",
      "Original English sentence: abroad were less varied than before and at home she had a mother and\n",
      "******************************\n",
      "Input Sentence: the possibility o hte brotherhood of mne united in the aim of\n",
      "Predicted Sentence: the possibility to the brotherwood of men united in the aim of \n",
      "Original English sentence: the possibility of the brotherhood of men united in the aim of\n",
      "******************************\n",
      "Input Sentence: I do not dispute taht but it cannot eb denied that court privileges\n",
      "Predicted Sentence: Is do not dispute that but it cannot be denied that court privilesed \n",
      "Original English sentence: I do not dispute that but it cannot be denied that court privileges\n",
      "******************************\n",
      "Input Sentence:      really bhis\n",
      "Predicted Sentence: V  V V  really his \n",
      "Original English sentence:      really this\n",
      "******************************\n",
      "Input Sentence: I come in kindness and unfeigned love\n",
      "Predicted Sentence: IF come in kindness and unfigined love \n",
      "Original English sentence: I come in kindness and unfeigned love\n",
      "******************************\n",
      "Input Sentence: FErmerly when going int aption Rostov had felt afraid now he had not\n",
      "Predicted Sentence: Frrmerly when going into aption Rostov had felt afraid now he had not \n",
      "Original English sentence: Formerly when going into action Rostov had felt afraid now he had not\n",
      "******************************\n",
      "Input Sentence: fo wait a minute lpease\n",
      "Predicted Sentence: fow wait as minute please \n",
      "Original English sentence: No wait a minute please\n",
      "******************************\n",
      "Input Sentence: quartermaster appearebd wth an ordre to move on to the little town of\n",
      "Predicted Sentence: quartermaster appeared with an order to move on to the little town of \n",
      "Original English sentence: quartermaster appeared with an order to move on to the little town of\n",
      "******************************\n",
      "Input Sentence: lying oH tCe wofls back among the dogs trying to seize her by the\n",
      "Predicted Sentence: lying Ho the wofls back among the dogs trying to seize her by the \n",
      "Original English sentence: lying on the wolfs back among the dogs trying to seize her by the\n",
      "******************************\n",
      "Input Sentence: plepsed Kto Gear it from him Again he honored him by touching his ear\n",
      "Predicted Sentence: pleased to hear it from him Again he honored him by touching his ear \n",
      "Original English sentence: pleased to hear it from him Again he honored him by touching his ear\n",
      "******************************\n",
      "Input Sentence: Prince Andrew bwed hi head in tkoen of having understood from the\n",
      "Predicted Sentence: Prince Andrew bed his head in token of having understood from the \n",
      "Original English sentence: Prince Andrew bowed his head in token of having understood from the\n",
      "******************************\n",
      "Input Sentence: of hte first TheiHr Other engagements were few as the style of living\n",
      "Predicted Sentence: of het first Their Other engagements were few as the style of living \n",
      "Original English sentence: of the first Their other engagements were few as the style of living\n",
      "******************************\n",
      "Input Sentence: sName instnt eh was dazzled by a great flash of flame and immediately a\n",
      "Predicted Sentence: same instent he was dazzled by as great flash of flame and immediately as \n",
      "Original English sentence: same instant he was dazzled by a great flash of flame and immediately a\n",
      "******************************\n",
      "Input Sentence: BSut ot confimr my curses Could I meet em\n",
      "Predicted Sentence: But ot confirm my curses Could I meet me \n",
      "Original English sentence: But to confirm my curses Could I meet em\n",
      "******************************\n",
      "Input Sentence: th enemy came wth jingling spurs u the steps of the porch despite\n",
      "Predicted Sentence: the enemy came with jinging surs up the steps off the porch despite \n",
      "Original English sentence: the enemy came with jingling spurs up the steps of the porch despite\n",
      "******************************\n",
      "Input Sentence: unreasonabl tohan a little child who playing with the parts of a\n",
      "Predicted Sentence: unreasonably than as little child who playing with the parts of as \n",
      "Original English sentence: unreasonable than a little child who playing with the parts of a\n",
      "******************************\n",
      "Input Sentence: Deniov considerep i dangerous to make a second attack for fear of\n",
      "Predicted Sentence: Denisov considered in dangerous to make as second attack for fear of \n",
      "Original English sentence: Denisov considered it dangerous to make a second attack for fear of\n",
      "******************************\n",
      "Input Sentence: wsa unCrateful and tuhat Mamma would never allow him to marry me but\n",
      "Predicted Sentence: was untrafted and that Mamma would never allow him to marry men but \n",
      "Original English sentence: was ungrateful and that Mamma would never allow him to marry me but\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "predicted_sentences = []\n",
    "actual_sentences = []\n",
    "count = 0\n",
    "\n",
    "test_sentences = pd.read_csv('Novel_dataset_errors_test_3.csv')\n",
    "\n",
    "for i, row in test_sentences.iterrows():\n",
    "    output = predict(row['input'])\n",
    "    predicted_sentences.append(output)\n",
    "    english_out = row['target'].split()\n",
    "    actual_sentences.append(english_out)\n",
    "    sentence = ''.join(output)\n",
    "    print('Input Sentence:',row['input'])\n",
    "    print('Predicted Sentence:',sentence)\n",
    "    print('Original English sentence:', row['target'])\n",
    "    print('*'*30)\n",
    "    count += 1\n",
    "    if count == 40:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5bNFQyuz9Aa"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "avg_score = 0\n",
    "for i in range(len(actual_sentences)):\n",
    "    score = sentence_bleu([actual_sentences[i]], predicted_sentences[i].split())\n",
    "    avg_score += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yUCr-G-z9Aa",
    "outputId": "8afd3f3d-f448-4ab6-a989-1f07d2c7486d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg BLEU Score of Encoder Decoder Model: 0.6783860821709433\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg BLEU Score of Encoder Decoder Model:\", (avg_score/(len(actual_sentences))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Tried\n",
    "\n",
    "- Basic Encoder Decoder Models - 1 layer, 2 layer\n",
    "- Encoder Decoder with Luong Attention - 1 layer, 2 layer\n",
    "- Transformer\n",
    "\n",
    "### Dataset Tried\n",
    "\n",
    "- Dataset of SMS\n",
    "- SMS + Augmented SMS Data\n",
    "- SMS + Augmented Novel Data\n",
    "- Pure Novel Dataset\n",
    "- Pure Novel Dataset + Augmentation with SMS language\n",
    "- Pure Novel Dataset + Augmentation with typo mistakes, letter addition/deletion, letter exchanges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "From the output seen in the training, several anaylsis of the model prediction are as follows:\n",
    "\n",
    "- The model is able to do better compared to previous models since we are training the model on corrputed words and target words rather than input sentences which are longer. \n",
    "- The model achieves a good accuracy of around ~99% but note that there are several paddings due to which the accuracy is shown higher.\n",
    "\n",
    "\n",
    "- Looking at the sentences, we see that errors where the letters are exchanged or letters are replaced with another letter the model is able to correct them to a very good extent\n",
    "- The model however does not perform that well when it encouters missing letters in a word or addition of letters in the word.\n",
    "- Each sentence had maximum of 3 errors introduced in them, the is able to correct 2 errors depending on the sentence and the vocabulary.\n",
    "\n",
    "- With larger non repeating, non augmented dataset the model will perform much better covering wide variety of errors and mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Spell_Checked.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
